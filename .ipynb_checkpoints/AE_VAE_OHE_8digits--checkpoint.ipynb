{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num=8):\n",
    "    \"\"\" Generate 'num' number of one-hot encoded integers. \"\"\" \n",
    "    x_train = np.eye(num)[np.arange(num)]                       # This is a simple way to one-hot encode integers\n",
    "    \n",
    "    # Repeat x_train multiple times for training\n",
    "    x_train = np.repeat(x_train, 100, axis=0)\n",
    "    \n",
    "    # The target is x_train itself!\n",
    "    x_target = x_train.copy()\n",
    "    return x_train, x_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 8\n",
    "np.random.seed(10)\n",
    "x_train, x_target = generate_data(num=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(800, 8)\n",
      "(800, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "latent_dims = 3\n",
    "num_epochs = 2000\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder Definition\n",
    "https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1\n",
    "\n",
    "https://gist.github.com/AFAgarap/4f8a8d8edf352271fa06d85ba0361f26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        #self.encoder_hidden_layer = nn.Linear(in_features=kwargs[\"input_shape\"],)\n",
    "        self.encoder_layer = nn.Linear(in_features=num, out_features = latent_dims)\n",
    "        nn.init.xavier_normal_(self.encoder_layer.weight)\n",
    "        self.decoder_layer = nn.Linear(in_features = latent_dims, out_features = num)\n",
    "        nn.init.xavier_normal_(self.decoder_layer.weight)\n",
    "    \n",
    "    def forward(self,features):\n",
    "        x_input = self.encoder_layer(features)\n",
    "        z = torch.sigmoid(x_input)\n",
    "        if z.size()[0] == 3:\n",
    "            z = z.view(1, 3)\n",
    "        #print(self.decoder_layer(z))\n",
    "        #recon = torch.sigmoid(self.decoder_layer(z))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        recon = softmax(self.decoder_layer(z))\n",
    "        return recon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Autoencoder(\n",
      "  (encoder_layer): Linear(in_features=8, out_features=3, bias=True)\n",
      "  (decoder_layer): Linear(in_features=3, out_features=8, bias=True)\n",
      ")>\n",
      "Number of parameters: 59\n"
     ]
    }
   ],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "AE = Autoencoder()\n",
    "AE = AE.to(device)\n",
    "num_params = sum(p.numel() for p in AE.parameters() if p.requires_grad)\n",
    "print(AE.parameters)\n",
    "print(\"Number of parameters: %d\" % num_params) #3*8 + 8 = 32, 8*3 + 3 = 27, 32+27\n",
    "\n",
    "# optimizer object\n",
    "optimizer = torch.optim.Adam(params = AE.parameters(), lr = learning_rate)\n",
    "#criterion = nn.CrossEntropyLoss()    # for target, does not accept a OHE vector\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/2000\tloss=-0.00206\tTest loss: -0.12681\n",
      "Epoch 201/2000\tloss=-0.00849\tTest loss: -0.52315\n",
      "Epoch 401/2000\tloss=-0.01334\tTest loss: -0.82287\n",
      "Epoch 601/2000\tloss=-0.01555\tTest loss: -0.95678\n",
      "Epoch 801/2000\tloss=-0.01602\tTest loss: -0.98563\n",
      "Epoch 1001/2000\tloss=-0.01616\tTest loss: -0.99457\n",
      "Epoch 1201/2000\tloss=-0.01622\tTest loss: -0.99789\n",
      "Epoch 1401/2000\tloss=-0.01624\tTest loss: -0.99917\n",
      "Epoch 1601/2000\tloss=-0.01624\tTest loss: -0.99967\n",
      "Epoch 1801/2000\tloss=-0.01625\tTest loss: -0.99987\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "x_train, x_target = generate_data(num=num)\n",
    "inds = list(range(x_train.shape[0]))\n",
    "N = x_train.shape[0] # 800\n",
    "freq = num_epochs // 10 # floor division\n",
    "\n",
    "loss_hist = []\n",
    "x_train = Variable(torch.from_numpy(x_train))\n",
    "x_target = Variable(torch.from_numpy(x_target))\n",
    "for epoch in range(num_epochs):\n",
    "    inds = np.random.permutation(inds)\n",
    "    x_train = x_train[inds]\n",
    "    x_train = x_train.to(device)\n",
    "    x_target = x_target[inds]\n",
    "    x_target = x_target.to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    num_batches = N / batch_size\n",
    "    for b in range(0, N, batch_size):\n",
    "        #get the mini-batch\n",
    "        x_batch = x_train[b: b+batch_size]\n",
    "        x_target_batch = x_target[b: b+batch_size]\n",
    "        \n",
    "        #feed forward\n",
    "        batch_recon = AE(x_batch.float())\n",
    "        \n",
    "        # Error\n",
    "        #Convert x_batch from OHE vectors to single scalar for target class, of each sample in batch \n",
    "        _, x_batch_targets = x_batch.max(dim=1)\n",
    "        #x_batch_targets = x_batch_targets.type(torch.LongTensor)\n",
    "        #x_batch_targets = x_batch_targets.to(device)\n",
    "        #print(batch_recon)\n",
    "        #print('break')\n",
    "        #print(x_batch)\n",
    "        #print(x_batch_targets)\n",
    "        train_loss = criterion(batch_recon, x_batch_targets)\n",
    "        #print(batch_recon.size())\n",
    "        #print(x_batch_targets.size())\n",
    "        loss += train_loss.item() / N # update epoch loss\n",
    "        \n",
    "        #Backprop the error, compute the gradient\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        \n",
    "        #update parameters based on gradient\n",
    "        optimizer.step()\n",
    "        \n",
    "    #Record loss per epoch        \n",
    "    loss_hist.append(loss)\n",
    "    \n",
    "    if epoch % freq == 0:\n",
    "        print()\n",
    "        print(\"Epoch %d/%d\\tloss=%.5f\" % (epoch + 1, num_epochs, loss), end='\\t', flush=True)\n",
    "        \n",
    "        #Test with all training data\n",
    "        train_recon = AE(x_train.float())\n",
    "        _, x_targets = x_target.max(dim=1)\n",
    "        l = criterion(train_recon, x_targets)\n",
    "        print(\"Test loss: {:.5f}\".format(l.item()), end='')\n",
    "    \n",
    "print(\"\\nTraining finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print prediction results:\n",
      "\tInput: [1. 0. 0. 0. 0. 0. 0. 0.] \n",
      "\t Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\tInput: [0. 1. 0. 0. 0. 0. 0. 0.] \n",
      "\t Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "\tInput: [0. 0. 1. 0. 0. 0. 0. 0.] \n",
      "\t Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "\tInput: [0. 0. 0. 1. 0. 0. 0. 0.] \n",
      "\t Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "\tInput: [0. 0. 0. 0. 1. 0. 0. 0.] \n",
      "\t Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\tInput: [0. 0. 0. 0. 0. 1. 0. 0.] \n",
      "\t Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\tInput: [0. 0. 0. 0. 0. 0. 1. 0.] \n",
      "\t Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "\tInput: [0. 0. 0. 0. 0. 0. 0. 1.] \n",
      "\t Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print prediction results:\")\n",
    "x_test = np.eye(num)[np.arange(num)]                        # Test data (one-hot encoded)\n",
    "x_test = Variable(torch.from_numpy(x_test))\n",
    "x_test = x_test.to(device)\n",
    "#np.set_printoptions(2)\n",
    "for x in x_test:\n",
    "    print(\"\\tInput: {} \\n\\t Output: {}\".format(x.cpu().detach().numpy(), np.round(AE(x.float()).cpu().detach().numpy()),decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract intermediate features using Forward Hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printnorm_encoder(self, input1, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('\\tInside ' + self.__class__.__name__ + ' forward')\n",
    "    #print('\\t input:', input1.cpu().detach().numpy())\n",
    "    print('\\t output rounded to 2 decimals:', np.round(output.cpu().detach().numpy(),decimals=2))\n",
    "    print('\\t output rounded to integer:', np.round(output.cpu().detach().numpy(),decimals=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inside_decoder(self, input1, output):\n",
    "    # input is a tuple of packed inputs\n",
    "    # output is a Tensor. output.data is the Tensor we are interested\n",
    "    print('\\tInside ' + self.__class__.__name__ + ' forward')\n",
    "    #print(input1[0].cpu().detach().numpy())\n",
    "    #print('\\t input:', input1.cpu().detach().numpy())\n",
    "    print('\\t output rounded to 2 decimals:', np.round(input1[0].cpu().detach().numpy(),2))\n",
    "    #print('\\t output rounded to integer:', input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT: [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[1. 1. 1.]]\n",
      "INPUT: [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[1. 0. 0.]]\n",
      "INPUT: [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[1. 1. 0.]]\n",
      "INPUT: [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[0. 0. 0.]]\n",
      "INPUT: [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[0. 1. 0.]]\n",
      "INPUT: [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[0. 1. 1.]]\n",
      "INPUT: [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[0. 0. 1.]]\n",
      "INPUT: [0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "\tInside Linear forward\n",
      "\t output rounded to 2 decimals: [[1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#AE.encoder_layer.register_forward_hook(printnorm_encoder)\n",
    "decoder_hook = AE.decoder_layer.register_forward_hook(inside_decoder)\n",
    "for x in x_test:\n",
    "    print('INPUT: {}'.format(x.cpu().detach().numpy()))\n",
    "    out = AE(x.float())\n",
    "    #print(out)\n",
    "decoder_hook.remove() #remove hook after use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dimensions set to 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Definition\n",
    "https://colab.research.google.com/github/smartgeometry-ucl/dl4g/blob/master/variational_autoencoder.ipynb#scrollTo=0psoODlF9S_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
