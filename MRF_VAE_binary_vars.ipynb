{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE_binary_vars",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNEIRtAHoq2iObBbFH+2HDG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE_binary_vars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c3459b3-0746-49a5-8244-5b329a25fb25"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "!pip install -i https://test.pypi.org/simple/ PPandas==0.0.1.7.1\n",
        "!pip install python-intervals\n",
        "!pip install geopandas\n",
        "!pip install geovoronoi\n",
        "import ppandas\n",
        "from ppandas import PDataFrame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: PPandas==0.0.1.7.1 in /usr/local/lib/python3.6/dist-packages (0.0.1.7.1)\n",
            "Requirement already satisfied: python-intervals in /usr/local/lib/python3.6/dist-packages (1.10.0.post1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (3.0.0.post1)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.18)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.3.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.7.1)\n",
            "Requirement already satisfied: geovoronoi in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1"
      },
      "source": [
        "# Function to create OHE dataset for specified attributes given a global df\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ac6b33-53e9-410d-ba26-59f08f5c2033"
      },
      "source": [
        "# Load global relation from github\n",
        "df = pd.read_csv(\"data_2_1000rows.csv\") # 3columns A,B,C that each contain values 0 to 1, block diagonal\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 500\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "#sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "#print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "#sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 2)\n",
            "     A  B\n",
            "37   1  1\n",
            "726  1  1\n",
            "846  1  1\n",
            "295  1  0\n",
            "924  1  0\n",
            "     A_0  A_1  B_0  B_1\n",
            "37     0    1    0    1\n",
            "726    0    1    0    1\n",
            "846    0    1    0    1\n",
            "295    0    1    1    0\n",
            "924    0    1    1    0\n",
            "..   ...  ...  ...  ...\n",
            "194    0    1    1    0\n",
            "136    0    1    0    1\n",
            "581    1    0    1    0\n",
            "662    1    0    1    0\n",
            "671    1    0    1    0\n",
            "\n",
            "[500 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up-Ps6PEoQB4"
      },
      "source": [
        "P(A,B) = \r\n",
        "*   P(A=0,B=0) = 0.3\r\n",
        "*P(A=0,B=1) = 0.1\r\n",
        "*P(A=1,B=0) = 0.2\r\n",
        "*P(A=1,B=1) = 0.4\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af11efb1-454a-4440-8d8a-c2016e0652cd"
      },
      "source": [
        "def groundTruth(df,query_attribute,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    \n",
        "    #q = inference.query(variables=['A','B','C'])\n",
        "    #joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=[query_attribute], evidence=evidence)\n",
        "    print(q)\n",
        "\n",
        "print('\\n P(B|A=0) Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':0})\n",
        "\n",
        "print('\\n P(A|B=0) Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':1})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " P(B|A=0) Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.7500 |\n",
            "+------+----------+\n",
            "| B(1) |   0.2500 |\n",
            "+------+----------+\n",
            "\n",
            " P(A|B=0) Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.3333 |\n",
            "+------+----------+\n",
            "| B(1) |   0.6667 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTvWAZ9UARW"
      },
      "source": [
        "# ppandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bto996MFUCnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96481b5b-706f-40ad-887f-596bd443714d"
      },
      "source": [
        "def ppandas_query(sample1_df,num_samples,query_attribute,evidence):\n",
        "    pd1 = PDataFrame(['B'],sample1_df)\n",
        "    q = pd1.query(['A','B'])\n",
        "    cols = q.columns.tolist()\n",
        "    q = q.rename(columns={q.columns[2]:'Probability(A,B)'})\n",
        "    #Reorder columns\n",
        "    q = q[['A','B','Probability(A,B)']]\n",
        "    q= q.sort_values(by=['A','B'])\n",
        "    #print(q)\n",
        "    #Sort rows in dataframe by descending order\n",
        "    print(\"\\n ppandas P({}|{}) , n={} \\n \".format(query_attribute,evidence,num_samples))\n",
        "    q1 = pd1.query([query_attribute],evidence_vars=evidence)\n",
        "    print(q1)\n",
        "    q1 = pd1.map_query([query_attribute],evidence_vars=evidence)\n",
        "    #pd_join.visualise()\n",
        "    return q1\n",
        "\n",
        "q1 = ppandas_query(sample1_df,num_samples,query_attribute='B',evidence={'A':0})\n",
        "q1 = ppandas_query(sample1_df,num_samples,query_attribute='B',evidence={'A':1})\n",
        "#print(ppandas_C)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ppandas P(B|{'A': 0}) , n=500 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.770732\n",
            "1  1.0        0.229268\n",
            "\n",
            " ppandas P(B|{'A': 1}) , n=500 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.318644\n",
            "1  1.0        0.681356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q"
      },
      "source": [
        "# Multivariate Normal\n",
        "Koller Equation 7.3: \\\\\n",
        "$P(z_A,z_B) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_A \\\\ \\mu_B \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{A} & \\Sigma_{AB} \\\\ \\Sigma_{BA} & \\Sigma_{B} \\end{array} \\right] \\right) $ \n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354) https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf: \\\\\n",
        "$P(z_A|z_B) = Normal_{z_A}(\\hat{\\mu}_A, \\hat{\\Sigma}_A)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_A = \\mu_A + \\Sigma_{AB} \\Sigma_{B}^{-1}(z_B - \\mu_B)$ \\\\\n",
        "$\\hat{\\Sigma}_A = \\Sigma_A - \\Sigma_{AB} \\Sigma_B^{-1} \\Sigma_{AB}^T$ \\\\\n",
        "\n",
        "$P(z_B|z_A) = Normal_{z_B}(\\hat{\\mu}_B, \\hat{\\Sigma}_B)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_B = \\mu_B + \\Sigma_{AB}^T \\Sigma_{A}^{-1}(z_A - \\mu_A)$ \\\\\n",
        "$\\hat{\\Sigma}_B = \\Sigma_B - \\Sigma_{AB}^T \\Sigma_A^{-1} \\Sigma_{AB}$ \\\\\n",
        "\n",
        "\n",
        "The output of the VAE encoders are assumed to be the mean and variance of the unary normal potentials in the MRF over the latent z's where:\n",
        "\n",
        "•\tMean: $\\mu_{A}$ and diagonal variance matrix: $\\Sigma_{A}$ are the outputs of the A encoder \\\\\n",
        "•\t$\\mu_{B}$,  $\\Sigma_{B}$ are the outputs of the B encoder \\\\\n",
        "\n",
        "\n",
        "The additional pairwise k-ary Normal potentials, which represent undirected graphical model structure between the latent A and latent B : \\\\\n",
        "•\t$\\Sigma_{AB}$ = $\\Sigma_{BA}^T$ \n",
        "\n",
        "If the latent space is dimension 3, each $\\mu \\in \\mathcal{R}^{1 \\times 3}$ and each $\\Sigma \\in \\mathcal{R}^{3 \\times 3}$.\n",
        "\n",
        "\n",
        "# Training the VAE-MRF\n",
        "Assuming no missing data. Training is done in two stages. The first stage learns marginal VAEs for each attribute. The second stage learns the covariance matrix $\\Sigma_{AB}$ to capture the intervariable dependencies between A and B.\n",
        "\n",
        "##Stage 1 - Marginal VAEs (Identical to Stage 1 VAEM)\n",
        "Train A and B VAEs separately.\n",
        "In each epoch, break the training data into batches. Each batch contains samples of OHE input $x_A$ or $x_B$:\n",
        "- Feed in $x_A$ or $x_B$ to their respective encoders to obtain either:\n",
        "  - $\\mu_A, \\Sigma_A$ from encoder A\n",
        "  - $\\mu_B, \\Sigma_B$ from encoder B\n",
        "\n",
        "- To reconstruct $x_A$ ($x_B$):\n",
        "  - Sample $z_A$ ($z_B$) using $\\mu_A, \\Sigma_A$ ($\\mu_B, \\Sigma_B$) through standard VAE reparameterization trick\n",
        "  - Feed $z_A$  ($z_B$) into the **A** (**B**) decoder to obtain the reconstruction $\\hat{x}_A$ ($\\hat{x}_B$)\n",
        "\n",
        "- Sum the losses (reconstruction error and KL-divergence) from either A or B  and backpropagate once per batch.\n",
        "\n",
        "For marginal VAEs, fix the parameters: encoder $\\phi$ and decoder $\\theta$.\n",
        "\n",
        "## Stage 2 - Intervariable Dependency CRF\n",
        "In each epoch, break the training data into batches. Each batch contains samples of OHE input $x_A$ and $x_B$. By reconstructing $x_A, x_B$ from $x_A$ and $x_B$, learn $\\Sigma_{AB}$:\n",
        "  - Feed entire batch of $x_A$ to marginal A encoder to obtain Monte Carlo emperical $\\mu_A, \\Sigma_A$\n",
        "  - Feed entire batch of $x_B$ to marginal B encoder to obtain Monte Carlo emperical $\\mu_B, \\Sigma_B$\n",
        "  - If memory allows - feed in entire train population of $x_A$ and $x_B$ for more reliable emperical estimates\n",
        "  - To reconstruct a specific $x_A$:\n",
        "      - Feed specific corresponding $x_B$ to marginal encoder to obtain sample $z_B$ (standard VAE reparameterization trick)\n",
        "      - Using $z_B,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_A$ from $P(z_A|z_B)$ (modified VAE reparameterization trick)\n",
        "      - Feed $z_A$ into the A decoder to obtain the reconstruction $\\hat{x}_A$\n",
        "\n",
        "  - To reconstruct $x_B$:\n",
        "    - Feed specific corresponding $x_A$ to marginal encoder to obtain sample $z_A$ (standard VAE reparameterization trick) \n",
        "    - Using $z_A,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$ (modified VAE reparameterization trick)\n",
        "    - Feed $z_B$ into the B decoder to obtain the reconstruction $\\hat{x}_B$\n",
        "\n",
        "\n",
        "Sum the losses (reconstruction error and KL-divergence) from both A and B and backpropagate once per batch.\n",
        "Repeat for each batch. \\\\\n",
        "\n",
        "Note that $\\mu_A$, $\\Sigma_A$, $\\mu_B$, $\\Sigma_B$ are fixed for each batch.  There is only one $\\Sigma_{AB}$ to be shared. \n",
        "\n",
        "# Stage 2 - Intervariable Dependency CRF (missing data at train time scenario, not implemented)\n",
        "Training the VAE-MRF on x_A only: \n",
        "- Feed entire batch of $x_A$ to marginal A encoder to obtain emperical $\\mu_A, \\Sigma_A$\n",
        "-  Feed entire batch of $x_B$ to marginal B encoder to obtain emperical $\\mu_B, \\Sigma_B$ (If no $x_B$ assume prior P(zB) = Normal (0, Identity))\n",
        "- Sample $z_B$ using $\\mu_B, \\Sigma_B$ (standard VAE reparameterization trick)\n",
        "- Using $z_B,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_A$ from $P(z_A|z_B)$ (modified VAE reparameterization trick)\n",
        "-  Feed $z_A$ into the A decoder to obtain the reconstruction $\\hat{x}_A$ for $x_A$\n",
        "- Sum the losses (reconstruction error and KL-divergence) from A and backpropagate once per batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y"
      },
      "source": [
        "# VAE Parameters\n",
        "num = 2 # digits from 0 to 1\n",
        "latent_dims = 1 # Latent z_A, z_B same dimension size\n",
        "num_epochs = 200\n",
        "batch_size = 25\n",
        "learning_rate = 1e-3 #1e-4\n",
        "use_gpu = True\n",
        "variational_beta = 0.001 #tuned 0.001"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifSVkjMe-lJj"
      },
      "source": [
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  CE = criterion(batch_recon, batch_targets)\r\n",
        "  #print(CE)\r\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\r\n",
        "  #print(KLd)\r\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd\r\n",
        "\r\n",
        "#Train marginal VAE\r\n",
        "def trainVAE(VAE, sample1_OHE, attribute: str):\r\n",
        "  print(\"\\nTraining marginal VAE for \" + attribute+ \" started!\")\r\n",
        "  VAE.train() #set model mode to train\r\n",
        "  optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\r\n",
        "  x = sample1_OHE.filter(like=attribute, axis=1).values\r\n",
        "  #sample2_OHE when do BC plate\r\n",
        "  \r\n",
        "  inds = list(range(x.shape[0]))\r\n",
        "  N = num_samples\r\n",
        "  freq = num_epochs // 10 # floor division\r\n",
        "\r\n",
        "  loss_hist = []\r\n",
        "  x = Variable(torch.from_numpy(x))\r\n",
        "  \r\n",
        "  for epoch in range(num_epochs):\r\n",
        "      #print('epoch' + str(epoch))\r\n",
        "      inds = np.random.permutation(inds)\r\n",
        "      x = x[inds]\r\n",
        "      x = x.to(device)\r\n",
        "      \r\n",
        "      loss = 0\r\n",
        "      CE = 0\r\n",
        "      KLd = 0\r\n",
        "      #num_batches = N / batch_size\r\n",
        "      for b in range(0, N, batch_size):\r\n",
        "          #get the mini-batch\r\n",
        "          x_batch = x[b: b+batch_size]\r\n",
        "          #feed forward\r\n",
        "          batch_recon,latent_mu,latent_logvar = VAE.forward(x_batch.float())\r\n",
        "          # Error\r\n",
        "          #Convert x_batch from OHE vectors to single scalar\r\n",
        "          # max returns index location of max value in each sample of batch \r\n",
        "          _, x_batch_targets = x_batch.max(dim=1)\r\n",
        "          train_CE, train_KLd, train_loss = vae_loss(batch_recon, x_batch_targets, latent_mu, latent_logvar)\r\n",
        "          loss += train_loss.item() / N # update epoch loss\r\n",
        "          CE += train_CE.item() / batch_size\r\n",
        "          KLd += train_KLd.item() / batch_size\r\n",
        "\r\n",
        "          #Backprop the error, compute the gradient\r\n",
        "          optimizer.zero_grad()\r\n",
        "          train_loss = train_loss\r\n",
        "          train_loss.backward()\r\n",
        "\r\n",
        "          #update parameters based on gradient\r\n",
        "          optimizer.step()\r\n",
        "          \r\n",
        "      #Record loss per epoch        \r\n",
        "      loss_hist.append(loss)\r\n",
        "      \r\n",
        "      if epoch % freq == 0:\r\n",
        "          print('')\r\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\r\n",
        "\r\n",
        "          #Test with all training data\r\n",
        "          VAE.eval()\r\n",
        "          train_recon, train_mu, train_logvar = VAE.forward(x.float())\r\n",
        "          _, x_targets = x.max(dim=1)\r\n",
        "          CE_,KLd,test_loss = vae_loss(train_recon, x_targets, train_mu, train_logvar)\r\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\r\n",
        "\r\n",
        "          #print('Visualize ' + attribute + 'predictions')\r\n",
        "          #print(train_recon[0:5])\r\n",
        "          #print(x_targets[0:5])\r\n",
        "\r\n",
        "  print(\"\\nTraining marginal VAE for \" + attribute+ \" finished!\")\r\n",
        "  #print(loss_hist)\r\n",
        "\r\n",
        "#Each attribute has a marginal VAE\r\n",
        "class marginal_VAE(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.latent_dims = latent_dims\r\n",
        "        self.fc1 = nn.Linear(num, latent_dims)\r\n",
        "        self.fc_mu = nn.Linear(latent_dims, latent_dims)\r\n",
        "        self.fc_logvar = nn.Linear(latent_dims, latent_dims)\r\n",
        "        self.fc_out = nn.Linear(latent_dims,num)\r\n",
        "    \r\n",
        "    #accepts OHE input of an attribute, returns mu and log variance\r\n",
        "    def encode(self, x):\r\n",
        "        h1 = torch.sigmoid(self.fc1(x))\r\n",
        "        return self.fc_mu(h1), self.fc_logvar(h1)\r\n",
        "\r\n",
        "    #Given mu and logvar generates latent z \r\n",
        "    def reparameterize(self, mu, logvar):\r\n",
        "        std = torch.exp(0.5*logvar) \r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return mu + eps*std\r\n",
        "\r\n",
        "    #Decodes latent z into reconstruction with dimension equal to num\r\n",
        "    def decode(self, z):\r\n",
        "        if z.size()[0] == self.latent_dims: #resize from [1] to [1,1]\r\n",
        "          z = z.view(1, self.latent_dims)\r\n",
        "        softmax = nn.Softmax(dim=1)  #normalizes reconstruction to range [0,1] and sum to 1\r\n",
        "        recon = softmax(self.fc_out(z))\r\n",
        "        return recon\r\n",
        "    \r\n",
        "    #Given x, returns: reconstruction x_hat, mu, log_var\r\n",
        "    def forward(self, x):\r\n",
        "        mu, logvar = self.encode(x)\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return self.decode(z), mu, logvar\r\n",
        "    \r\n",
        "    #Given x, returns latent z\r\n",
        "    def latent(self, x):\r\n",
        "        mu, logvar = self.encode(x)\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return z\r\n",
        "    \r\n",
        "    # ignore latent_mu, latent_logvar, instead generate z values from standard normal\r\n",
        "    def sample(self, num_samples):\r\n",
        "      z = torch.randn(num_samples, self.latent_dims)\r\n",
        "      z = z.to(device)\r\n",
        "      samples = self.decode(z)\r\n",
        "      return samples"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB"
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.latent_dims = latent_dims\n",
        "        #Marginal VAEs\n",
        "        self.VAE_A = marginal_VAE()\n",
        "        self.VAE_B = marginal_VAE()\n",
        "        #Emperical mu and logvar\n",
        "        self.muA_emp = 0\n",
        "        self.muB_emp = 0\n",
        "        self.logvarA_emp = 0\n",
        "        self.logvarB_emp = 0\n",
        "        #Sigma_{AB} = Sigma_{BA}^T\n",
        "        self.covarianceAB = torch.randn(size=(self.latent_dims,self.latent_dims))\n",
        "        self.covarianceAB = torch.nn.Parameter(self.covarianceAB,requires_grad=True)\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "\n",
        "    #Stage 1 - Train Marginal VAEs and then freeze parameters\n",
        "    def train_marginals(self):\n",
        "        trainVAE(self.VAE_A,sample1_OHE, 'A')\n",
        "        trainVAE(self.VAE_B,sample1_OHE, 'B')\n",
        "\n",
        "    #Finds emperical mean and logvar of each attribute for entire population\n",
        "    def emp_mu_logvar(self,x,attribute):\n",
        "      if attribute == 'A':\n",
        "        muA, logvarA = self.encode(x, attribute)\n",
        "        self.muA_emp = torch.mean(muA,0,keepdim=True) #need to modify if muA is more than 1 dimension\n",
        "        self.logvarA_emp = torch.mean(logvarA,0,keepdim=True)\n",
        "        print('Emperical A mu and logvar')\n",
        "        print(self.muA_emp)\n",
        "        print(self.logvarA_emp)\n",
        "      elif attribute == 'B':\n",
        "        muB, logvarB = self.encode(x, attribute)\n",
        "        self.muB_emp = torch.mean(muB,0,keepdim=True)\n",
        "        self.logvarB_emp = torch.mean(logvarB,0,keepdim=True)\n",
        "        print('Emperical B mu and logvar')\n",
        "        print(self.muB_emp)\n",
        "        print(self.logvarB_emp)\n",
        "      return\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    # Attribute is the attribute of the returned z_cond \n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #log-space for numerical stability.\n",
        "        logvarA = torch.exp(0.5*logvarA)\n",
        "        logvarB = torch.exp(0.5*logvarB)\n",
        "        covarianceA = torch.diag_embed(logvarA) #Convert logvar vector to diagonal matrix\n",
        "        covarianceB = torch.diag_embed(logvarB) #batch_size,3,3\n",
        "        muA = muA.unsqueeze(2)\n",
        "        muB = muB.unsqueeze(2)\n",
        "        z = z.unsqueeze(2)\n",
        "        if attribute == 'A':\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                    torch.inverse(covarianceB)),\n",
        "                                      (z - muB)) # z is zB\n",
        "          logvar_cond = covarianceA - torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                                torch.inverse(covarianceB)),\n",
        "                                                  torch.transpose(self.covarianceAB,0,1))\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims) # regularization\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1),\n",
        "                                                    torch.inverse(covarianceA)), \n",
        "                                       (z - muA)) # z is zA\n",
        "          logvar_cond = covarianceB - torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1), \n",
        "                                                              torch.inverse(covarianceA)),\n",
        "                                                 self.covarianceAB)\n",
        "              # logvar_cond is not a diagonal covariance matrix\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims)\n",
        "\n",
        "        # METHOD1: re-parameterization trick to sample z_cond\n",
        "        eps = torch.randn_like(mu_cond) #64x3x1, 64x3x3 if use logvar_cond\n",
        "        z_cond = mu_cond + torch.matmul(logvar_cond,eps) #64x3x1\n",
        "        z_cond = z_cond.squeeze(2) #64x3\n",
        "        return z_cond\n",
        "\n",
        "    #return mu, logvar\n",
        "    def encode(self, x, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.encode(x)\n",
        "      elif attribute =='B':\n",
        "        return self.VAE_B.encode(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "    \n",
        "    #return reconstruction\n",
        "    def decode(self, z, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.decode(z)\n",
        "      elif attribute =='B':\n",
        "        return self.VAE_B.decode(z)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "    \n",
        "    #Given xA, xB and attribute to reconstruct, return reconstruction\n",
        "    def forward(self, xA, xB, attribute):\n",
        "      muA, logvarA = self.encode(xA, attribute='A') #logvar is size [64,3]\n",
        "      muB, logvarB = self.encode(xB, attribute='B')\n",
        "      # Take batch emperical average of mus and logvars\n",
        "      #size_placeholder = muA.size() #[batch_size,latent_dims]\n",
        "      #muA_emp = torch.mean(muA,0,keepdim=True).repeat(size_placeholder,1) #(batchsize,latent_dims) all repeated values of avg\n",
        "      #logvarA_emp = torch.mean(logvarA,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #muB_emp = torch.mean(muB,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #logvarB_emp = torch.mean(logvarB,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #print(logvarA)\n",
        "      if attribute == 'A':\n",
        "        zB = self.VAE_B.reparameterize(muB, logvarB)\n",
        "        zA = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zB, attribute)\n",
        "        return self.decode(zA,attribute), self.muA_emp, self.logvarA_emp #should error use emperical avg or not?\n",
        "      elif attribute == 'B':\n",
        "        zA = self.VAE_A.reparameterize(muA, logvarA)\n",
        "        zB = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zA, attribute)\n",
        "        return self.decode(zB,attribute), self.muB_emp, self.logvarB_emp\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    def latent(self,x,attribute):\n",
        "      if attribute == 'A':\n",
        "          return self.VAE_A.latent(x)\n",
        "      elif attribute == 'B':\n",
        "        return self.VAE_B.latent(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    #Given x, returns: reconstruction x_hat, mu, log_var\n",
        "    def forward_single_attribute(self, x, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.forward(x)\n",
        "      elif attribute == 'B':\n",
        "        return self.VAE_B.forward(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    def query_single_attribute(self, x_evidence, evidence_attribute):\n",
        "      if evidence_attribute =='A':\n",
        "        muA,logvarA = self.encode(x_evidence, evidence_attribute)\n",
        "        #muB = torch.zeros(muA.size()) #100x3\n",
        "        #logvarB = torch.ones(muA.size()) #100x3\n",
        "        zA = self.VAE_A.reparameterize(muA, logvarA)\n",
        "        #Use emperical mus and logvars\n",
        "        zB = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zA, attribute='B')\n",
        "        return self.decode(zB,attribute='B')\n",
        "\n",
        "      elif evidence_attribute =='B':\n",
        "        muB,logvarB = self.encode(x_evidence, evidence_attribute)\n",
        "        zB = self.VAE_B.reparameterize(muB, logvarB)\n",
        "        zA = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zB, attribute='A')\n",
        "        return self.decode(zA,attribute='A')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01"
      },
      "source": [
        "def trainVAE_MRF(VAE_MRF):\n",
        "  VAE_MRF.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  #Calculate mu_emp and logvar_emp for all attributes (entire sample)\n",
        "  VAE_MRF.emp_mu_logvar(xA.float(),attribute='A')\n",
        "  VAE_MRF.emp_mu_logvar(xB.float(),attribute='B')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      #print('epoch' + str(epoch))\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "\n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward, should latent mu and logvar be the same for every recon, yes since want to learn covariance accurately?\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE_MRF.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE_MRF.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "\n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          loss += train_loss_A.item() / batch_size # update epoch loss\n",
        "          loss += train_loss_B.item() / batch_size\n",
        "          CE += train_CE_A.item() / batch_size\n",
        "          CE += train_CE_B.item() / batch_size \n",
        "          KLd += train_KLd_A.item() / batch_size\n",
        "          KLd += train_KLd_B.item() / batch_size\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print('')\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "\n",
        "          #Test with all training data\n",
        "          VAE_MRF.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE_MRF.forward(xA.float(),xB.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE_MRF.forward(xA.float(),xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_reconA, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_reconB, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining MRF finished!\")\n",
        "  #print(loss_hist)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bca2052-e8a4-43fe-ca89-d5f2e78f89e4"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE_MRF = VariationalAutoencoder_MRF()\n",
        "VAE_MRF = VAE_MRF.to(device)\n",
        "\n",
        "VAE_MRF.train_marginals() #Stage 1, then freeze marginal VAEs\n",
        "print('Parameters for Marginal VAEs fixed')\n",
        "for param in VAE_MRF.VAE_A.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in VAE_MRF.VAE_B.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "num_params = sum(p.numel() for p in VAE_MRF.parameters() if p.requires_grad)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "#for param in VAE_MRF.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE_MRF.parameters()))\n",
        "#print(VAE_MRF.parameters)\n",
        "\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, VAE_MRF.parameters()), lr = learning_rate)\n",
        "print(\"CovarianceAB before training\")\n",
        "print(VAE_MRF.covarianceAB.cpu().detach().numpy())\n",
        "#num_epochs = 5000\n",
        "trainVAE_MRF(VAE_MRF)\n",
        "print(\"CovarianceAB after training\")\n",
        "print(VAE_MRF.covarianceAB.cpu().detach().numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training marginal VAE for A started!\n",
            "\n",
            "Epoch 1/200\t CE: 0.59906, KLd: 0.00369, Train loss=0.03014\t\t CE: 0.59906, KLd: 0.08795, Test loss: 0.84062\n",
            "Epoch 21/200\t CE: 0.55025, KLd: 0.00041, Train loss=0.02753\t\t CE: 0.55025, KLd: 0.00979, Test loss: 0.68316\n",
            "Epoch 41/200\t CE: 0.52857, KLd: 0.00047, Train loss=0.02645\t\t CE: 0.52857, KLd: 0.01201, Test loss: 0.68569\n",
            "Epoch 61/200\t CE: 0.50638, KLd: 0.00227, Train loss=0.02543\t\t CE: 0.50638, KLd: 0.05909, Test loss: 0.68675\n",
            "Epoch 81/200\t CE: 0.42521, KLd: 0.00859, Train loss=0.02169\t\t CE: 0.42521, KLd: 0.22216, Test loss: 0.74553\n",
            "Epoch 101/200\t CE: 0.31226, KLd: 0.01792, Train loss=0.01651\t\t CE: 0.31226, KLd: 0.45379, Test loss: 0.83721\n",
            "Epoch 121/200\t CE: 0.28187, KLd: 0.02401, Train loss=0.01529\t\t CE: 0.28187, KLd: 0.60355, Test loss: 0.94937\n",
            "Epoch 141/200\t CE: 0.26576, KLd: 0.02666, Train loss=0.01462\t\t CE: 0.26576, KLd: 0.66728, Test loss: 1.00155\n",
            "Epoch 161/200\t CE: 0.26016, KLd: 0.02744, Train loss=0.01438\t\t CE: 0.26016, KLd: 0.68631, Test loss: 1.01195\n",
            "Epoch 181/200\t CE: 0.25987, KLd: 0.02720, Train loss=0.01435\t\t CE: 0.25987, KLd: 0.67924, Test loss: 1.00209\n",
            "Training marginal VAE for A finished!\n",
            "\n",
            "Training marginal VAE for B started!\n",
            "\n",
            "Epoch 1/200\t CE: 0.58438, KLd: 0.00348, Train loss=0.02939\t\t CE: 0.58438, KLd: 0.08174, Test loss: 0.81235\n",
            "Epoch 21/200\t CE: 0.56188, KLd: 0.00040, Train loss=0.02811\t\t CE: 0.56188, KLd: 0.00977, Test loss: 0.71448\n",
            "Epoch 41/200\t CE: 0.54846, KLd: 0.00128, Train loss=0.02749\t\t CE: 0.54846, KLd: 0.03456, Test loss: 0.72183\n",
            "Epoch 61/200\t CE: 0.45039, KLd: 0.00965, Train loss=0.02300\t\t CE: 0.45039, KLd: 0.24924, Test loss: 0.80266\n",
            "Epoch 81/200\t CE: 0.32882, KLd: 0.01969, Train loss=0.01743\t\t CE: 0.32882, KLd: 0.49749, Test loss: 0.91383\n",
            "Epoch 101/200\t CE: 0.28270, KLd: 0.02610, Train loss=0.01544\t\t CE: 0.28270, KLd: 0.65569, Test loss: 1.01177\n",
            "Epoch 121/200\t CE: 0.27114, KLd: 0.02877, Train loss=0.01500\t\t CE: 0.27114, KLd: 0.72025, Test loss: 1.05335\n",
            "Epoch 141/200\t CE: 0.26347, KLd: 0.02947, Train loss=0.01465\t\t CE: 0.26347, KLd: 0.73642, Test loss: 1.06402\n",
            "Epoch 161/200\t CE: 0.26297, KLd: 0.02929, Train loss=0.01461\t\t CE: 0.26297, KLd: 0.73344, Test loss: 1.05902\n",
            "Epoch 181/200\t CE: 0.25791, KLd: 0.02885, Train loss=0.01434\t\t CE: 0.25791, KLd: 0.72079, Test loss: 1.04448\n",
            "Training marginal VAE for B finished!\n",
            "Parameters for Marginal VAEs fixed\n",
            "Number of parameters: 1\n",
            "CovarianceAB before training\n",
            "[[2.2157948]]\n",
            "Emperical A mu and logvar\n",
            "tensor([[0.1855]])\n",
            "tensor([[-1.8896]])\n",
            "Emperical B mu and logvar\n",
            "tensor([[0.1083]])\n",
            "tensor([[-1.6868]])\n",
            "\n",
            "Epoch 1/200\t CE: 1.28159, KLd: 0.00078, Train loss=1.28238\t\t CE: 1.62252, KLd: 0.00078, Test loss: 1.62350\n",
            "Epoch 21/200\t CE: 1.34857, KLd: 0.00078, Train loss=1.34935\t\t CE: 1.65707, KLd: 0.00078, Test loss: 1.65804\n",
            "Epoch 41/200\t CE: 1.38018, KLd: 0.00078, Train loss=1.38096\t\t CE: 1.65609, KLd: 0.00078, Test loss: 1.65707\n",
            "Epoch 61/200\t CE: 1.29864, KLd: 0.00078, Train loss=1.29942\t\t CE: 1.59036, KLd: 0.00078, Test loss: 1.59134\n",
            "Epoch 81/200\t CE: 1.31301, KLd: 0.00078, Train loss=1.31380\t\t CE: 1.56842, KLd: 0.00078, Test loss: 1.56940\n",
            "Epoch 101/200\t CE: 1.32885, KLd: 0.00078, Train loss=1.32964\t\t CE: 1.67347, KLd: 0.00078, Test loss: 1.67445\n",
            "Epoch 121/200\t CE: 1.27274, KLd: 0.00078, Train loss=1.27353\t\t CE: 1.63378, KLd: 0.00078, Test loss: 1.63476\n",
            "Epoch 141/200\t CE: 1.28446, KLd: 0.00078, Train loss=1.28524\t\t CE: 1.64414, KLd: 0.00078, Test loss: 1.64512\n",
            "Epoch 161/200\t CE: 1.30141, KLd: 0.00078, Train loss=1.30220\t\t CE: 1.62200, KLd: 0.00078, Test loss: 1.62298\n",
            "Epoch 181/200\t CE: 1.35963, KLd: 0.00078, Train loss=1.36042\t\t CE: 1.59100, KLd: 0.00078, Test loss: 1.59198\n",
            "Training MRF finished!\n",
            "CovarianceAB after training\n",
            "[[1.9804316]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKa-T94O5mXH"
      },
      "source": [
        "# P(A,B) Multivariate Gaussian Ground Truth (1000 data points)\r\n",
        "## Mean: \r\n",
        "[0.6 0.5]\r\n",
        "\r\n",
        "##Covariance: \r\n",
        "\r\n",
        "[[0.24024024, 0.1001001 ]\r\n",
        "\r\n",
        "[0.1001001,  0.25025025]]\r\n",
        "\r\n",
        "# Hardcode Ground truth logvar,mu, Covariance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxjVeK606_Ub"
      },
      "source": [
        "VAE_MRF.eval()\r\n",
        "hardcode = False\r\n",
        "if hardcode == True:\r\n",
        "  with torch.no_grad():\r\n",
        "      #VAE_MRF.covarianceAB = torch.nn.Parameter(torch.tensor(0.1001001))\r\n",
        "      #VAE_MRF.covarianceAB = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(VAE_MRF.covarianceAB,0),0))\r\n",
        "      VAE_MRF.covarianceAB = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.1001001),0),0))\r\n",
        "      VAE_MRF.muA_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.6),0),0))\r\n",
        "      VAE_MRF.muB_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.5),0),0))\r\n",
        "      VAE_MRF.logvarA_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.24024024),0),0))\r\n",
        "      VAE_MRF.logvarB_emp =torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.25025025),0),0))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkKiDijtuUHt"
      },
      "source": [
        "## Check encoder, decoders work on their own\r\n",
        "It appears the marginal VAEs converges to a local minimum with accurate reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e52f13d-f985-4a8b-aa99-f2b3196bf901"
      },
      "source": [
        "x_test = np.eye(num)[np.arange(num)]                        # Test data (one-hot encoded)\n",
        "x_test = Variable(torch.from_numpy(x_test))\n",
        "x_test = x_test.to(device)\n",
        "\n",
        "print(\"Print prediction results for A only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE_MRF.forward_single_attribute(x=x.float(), attribute='A')[0].cpu().detach().numpy(),decimals=2)))\n",
        "\n",
        "print(\"Print prediction results for B only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE_MRF.forward_single_attribute(x=x.float(), attribute='B')[0].cpu().detach().numpy(),decimals=2)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print prediction results for A only:\n",
            "\tInput: [1. 0.] \t Output: [[1. 0.]]\n",
            "\tInput: [0. 1.] \t Output: [[0.01 0.99]]\n",
            "Print prediction results for B only:\n",
            "\tInput: [1. 0.] \t Output: [[1. 0.]]\n",
            "\tInput: [0. 1.] \t Output: [[0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbLTCH8lrJe"
      },
      "source": [
        "# Visualize Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae0jQpqykvUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "9423264e-6be8-44ce-bcd1-046fb1ca8e5f"
      },
      "source": [
        "xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "xA = Variable(torch.from_numpy(xA))\n",
        "xB = Variable(torch.from_numpy(xB))\n",
        "\n",
        "np_zA = np.empty(0)\n",
        "for x in xA:\n",
        "  zA = VAE_MRF.latent(x.float(), attribute='A')\n",
        "  #print(z)\n",
        "  np_zA = np.concatenate((np_zA, zA.cpu().detach().numpy()))\n",
        "np_zA = np_zA.reshape(num_samples,latent_dims)\n",
        "\n",
        "if latent_dims==1:\n",
        "  plt.plot(np_zA, 'o', color='black');\n",
        "elif latent_dims ==2:\n",
        "  plt.plot(np_zA[:,0], np_zA[:,1],'o', color='black');\n",
        "elif latent_dims ==3:\n",
        "  from mpl_toolkits.mplot3d import Axes3D\n",
        "  fig = plt.figure()\n",
        "  ax = Axes3D(fig)\n",
        "  #t = np.arange(1000)\n",
        "  ax.scatter(np_zA[:,0], np_zA[:,1], np_zA[:,2])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBTljFA9YMa"
      },
      "source": [
        "# Query P(B|A=0).\n",
        "##Ground truth: \n",
        "\n",
        "P(B=0|A=0) = 0.75\n",
        "\n",
        "P(B=1|A=0) = 0.25\n",
        "\n",
        "\n",
        "Feed nothing into B encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZdoZXu9biT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44e8840-e200-4fd7-c05f-4968b8489f3c"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(10000,1)\n",
        "print('A evidence input, first 5 rows')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "\n",
        "xB_query = VAE_MRF.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 rows\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], dtype=torch.float64)\n",
            "B query output:\n",
            "[[1.   0.  ]\n",
            " [1.   0.  ]\n",
            " [0.01 0.99]\n",
            " [1.   0.  ]\n",
            " [1.   0.  ]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.7828, 0.2172], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 7834, 1: 2166}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQ15yUZnHsc"
      },
      "source": [
        "# Query P(B|A=1), \n",
        "## Groundtruth: \n",
        "\n",
        "P(B=0|A=1) = 1/3\n",
        "\n",
        "P(B=1|A=1) = 2/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFsGFCqQmIZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c82aab-2b0b-4878-ecff-2da1487efc0f"
      },
      "source": [
        "xA_evidence = x_test[1] #Evidence is A=1\n",
        "xA_evidence = xA_evidence.repeat(10000,1)\n",
        "print('A evidence input, first 5 rows')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "\n",
        "xB_query = VAE_MRF.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 rows\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.]], dtype=torch.float64)\n",
            "B query output:\n",
            "[[1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.2902, 0.7098], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2899, 1: 7101}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gVDBBLmw7u"
      },
      "source": [
        "Notice that the VAE_MRF can answer the query, but not as accurately as ppandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5whHhIl14l5"
      },
      "source": [
        "# Query P(B|A=1,B=1)\r\n",
        "Feed both A and B, correctly identifies correct B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPPraAN111xK",
        "outputId": "ef91c30d-a7c9-47c7-d62a-02878e7832bb"
      },
      "source": [
        "xA_evidence = x_test[1] #Evidence is A=1\r\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\r\n",
        "\r\n",
        "xB_evidence = x_test[1] #Evidence is A=1\r\n",
        "xB_evidence = xB_evidence.repeat(10000,1)\r\n",
        "\r\n",
        "xB_query,_,_ = VAE_MRF.forward(xA_evidence.float(),xB_evidence.float(), 'A')\r\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\r\n",
        "print(xB_query.size())\r\n",
        "\r\n",
        "#Averaging all xB_query\r\n",
        "print('xB_query mean of each column:')\r\n",
        "print(torch.mean(xB_query,0))\r\n",
        "\r\n",
        "#Taking max of each row in xB_query and counting times each element is max\r\n",
        "print('xB_query count of when each column is max:')\r\n",
        "_,indices_max =xB_query.max(dim=1) \r\n",
        "#print(indices_max.numpy())\r\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\r\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.2282, 0.7718], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2281, 1: 7719}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMp0BWBo3po"
      },
      "source": [
        "#Query P(A|B= -1)\n",
        "Try feeding into B encoder negative ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5B_9zMpBib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc75d5f-1b70-4f7d-f86d-03a1e7adacd5"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "xB = torch.tensor([0,0])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,0])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,1]) # if feed in valid input, get correct result\n",
        "xB = xB.repeat(1000,1)\n",
        "\n",
        "xB_query,_,_ = VAE_MRF.forward(xA_evidence.float(),xB.float(), attribute='B')\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.7887, 0.2113], grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZJqFYQKqEWZ"
      },
      "source": [
        "- No matter xA evidence, if B encoder always given -1's B decoder same xB\n",
        "- No matter xA evidence, if B encoder always given 0's B decoder returns same xB\n",
        "- If feed in valid xB as evidence, then get correct xB as expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niyylLQg52C9"
      },
      "source": [
        "# Querying the VAE-MRF\r\n",
        "Once  the VAE-MRF is trained, to query P(B|A=0=(1,0,0,0,0,0,0,0))\r\n",
        "- Feed $x_A$ into the A encoder to obtain $\\mu_A, \\Sigma_A$\r\n",
        "- Sample $z_A$ using $\\mu_A, \\Sigma_A$ (standard VAE reparameterization trick)\r\n",
        "- Since no input $x_B$ to the B encoder, assume $\\mu_B, \\Sigma_B$ come from the prior P(z) = Normal (0, Identity)\r\n",
        "- Using $z_A, \\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$\r\n",
        "- Feed $z_B$ into the B decoder to obtain $\\hat{x}_B$ \\\\\r\n",
        "\r\n",
        "Repeat, feeding in evidence $x_A$ multiple times to the VAE-MRF to obtain a probability distribution $P(\\hat{x}_B|x_A)$\r\n",
        "\r\n",
        "# Extension to Two Datasets AB and BC (not yet implemented)\r\n",
        "$P(z_A,z_B,z_C) = Normal\r\n",
        "\\left(\\left( \\begin{array}{r} \\mu_A \\\\ \\mu_B \\\\ \\mu_C \\end{array} \\right), \r\n",
        "\\left[ \\begin{array}{r} \\Sigma_{A} & \\Sigma_{AB} & 0 \\\\ \\Sigma_{BA} & \\Sigma_{B} & \\Sigma_{BC}  \\\\ 0 & \\Sigma_{CB} & \\Sigma_{C} \\end{array} \\right] \\right) $ \r\n",
        "\r\n",
        "In addition to the AB VAE-MRF: \\\\\r\n",
        "  - $\\mu_{C}$,  $\\Sigma_{C}$ are the outputs of the C encoder \\\\\r\n",
        "  -\t$\\Sigma_{BC}$ = $\\Sigma_{CB}^T$ \r\n",
        "\r\n",
        "## Training the ABC VAE-MRF \r\n",
        "First sample $x_B$ from either the AB or BC dataset. Then using $x_B$, sample $x_A$ from the AB dataset and sample $x_C$ from the BC dataset.\r\n",
        "\r\n",
        "- As given previously, feed $x_A, x_B$ to their respective encoders to obtain  $\\mu_A, \\Sigma_A,  \\mu_B, \\Sigma_B$ and obtain reconstructions $\\hat{x_A}, \\hat{x_B}$. Then sum the losses (reconstruction error and KL-divergence) from both A and B  and backpropagate once per batch\r\n",
        "\r\n",
        "- Feed in $x_C$ and $x_B$ to their respective encoders to:\r\n",
        "  - obtain $\\mu_C, \\Sigma_C$ from encoder C\r\n",
        "  - obtain $\\mu_B, \\Sigma_B$ from encoder B\r\n",
        "\r\n",
        "- To reconstruct $x_C$:\r\n",
        "  - Sample $z_B$ using $\\mu_B, \\Sigma_B$ (standard VAE reparameterization trick)\r\n",
        "  - Using $z_B,\\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_C$ from $P(z_C|z_B)$ (modified VAE reparameterization trick)\r\n",
        "  - Feed $z_C$ into the C decoder to obtain the reconstruction $\\hat{x}_C$ for $x_C$\r\n",
        "\r\n",
        "- To reconstruct $x_B$:\r\n",
        "  - Sample $z_C$ using $\\mu_C, \\Sigma_C$ (standard VAE reparameterization trick)\r\n",
        "  - Using $z_C,\\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_C)$ (modified VAE reparameterization trick)\r\n",
        "  - Feed $z_B$ into the B decoder to obtain the reconstruction $\\hat{x}_B$ for $x_B$\r\n",
        "\r\n",
        "- Sum the losses (reconstruction error and KL-divergence) from both B and C  and backpropagate once per batch\r\n",
        "\r\n",
        "## Querying the ABC VAE-MRF\r\n",
        "Once  the VAE-MRF is trained, to query P(C|A=0=(1,0,0,0,0,0,0,0))\r\n",
        "- Feed $x_A$ into the A encoder to obtain $\\mu_A, \\Sigma_A$\r\n",
        "- Sample $z_A$ using $\\mu_A, \\Sigma_A$ (standard VAE reparameterization trick)\r\n",
        "- Since no input $x_B, x_C$ to the B or C encoders, assume $\\mu_B, \\Sigma_B$ and $\\mu_C, \\Sigma_C$ come from the prior P(z) = Normal (0, Identity)\r\n",
        "- Using $z_A, \\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$\r\n",
        "- Using $z_B, \\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_C$ from $P(z_C|z_B)$\r\n",
        "- Feed $z_C$ into the C decoder to obtain $\\hat{x}_C$ \\\\\r\n",
        "\r\n",
        "Repeat, feeding in evidence $x_A$ multiple times to the VAE-MRF to obtain a probability distribution $P(\\hat{x}_B|x_A)$\r\n",
        "\r\n",
        "# Notes\r\n",
        "\r\n",
        "A symmetric matrix is positive definite if:\r\n",
        "\r\n",
        "- all the diagonal entries are positive, and\r\n",
        "- each diagonal entry is greater than the sum of the absolute values of all other entries in the corresponding row/column.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPKlzMCE8abG"
      },
      "source": [
        "# Questions and Notes\n",
        "\n",
        "Requires alternating between AB and BC samples where B is the same.\n",
        "\n",
        "Have a separate plate for each dataset.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "How to handle datasets with 3 dimensions.\n",
        "Latent edges between A,B,C (clique)?\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgk-LlXB64eb"
      },
      "source": [
        "# To Do\n",
        "\n",
        "- Query P(A|B=0)\n",
        "- Add BC Plate\n",
        "- Visualize latent space\n",
        "- Try more than 1 sample when sampling zA and zB\n",
        "- During training, try reconstructing A given only x_B and reconstructing B given only x_A. I believe feeding in A (and B) to reconstruct A during train time does not match what is required of the model during test time where we feed in only B to reconstruct A.\n",
        "- Modifying variational_beta to lowest value that reconstructions were valid did not change ressults (0.0001), any higher variational_beta gave poor reconstructions.\n",
        "- Check if training on only A improves performance\n",
        "- Formalize in Overleaf\n",
        "- Answer general research questions\n",
        "- Try different likelihood functions (bernoulli, gaussian)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ_f2Kmg7H9O"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}