{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE_binary_vars",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPa4sV74QMV6LJzshP5+6y4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE_binary_vars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4729c0-cfb9-4795-c8ce-ccd4bae24232"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "!pip install -i https://test.pypi.org/simple/ PPandas==0.0.1.7.1\n",
        "!pip install python-intervals\n",
        "!pip install geopandas\n",
        "!pip install geovoronoi\n",
        "import ppandas\n",
        "from ppandas import PDataFrame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: PPandas==0.0.1.7.1 in /usr/local/lib/python3.6/dist-packages (0.0.1.7.1)\n",
            "Requirement already satisfied: python-intervals in /usr/local/lib/python3.6/dist-packages (1.10.0.post1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.2)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (3.0.0.post1)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.18)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.1.5)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pyproj>=2.2.0->geopandas) (2020.12.5)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.3.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.7.1)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.19.5)\n",
            "Requirement already satisfied: geovoronoi in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1"
      },
      "source": [
        "# Function to create OHE dataset for specified attributes given a global df\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc2ba546-d4a1-4ef9-ee3e-0c1aab645a7a"
      },
      "source": [
        "#Hardcode 2x2 P(A,B)\n",
        "# Load global relation from github\n",
        "from numpy import genfromtxt\n",
        "data_2 = genfromtxt('https://raw.githubusercontent.com/Kwanikaze/vpandas/master/data_2.csv?token=ADHT6UCKSGOEANAAQWTKGL3ACDPPS', delimiter=',',skip_header=1)\n",
        "data_2_1000 = np.tile(data_2, (100, 1))\n",
        "mean = np.mean(data_2_1000, axis=0)\n",
        "cov = np.cov(data_2_1000, rowvar=0)\n",
        "print(\"Mean Vector\")\n",
        "print(mean)\n",
        "print(\"Covariance Matrix\")\n",
        "print(cov)\n",
        "#print(data_2.shape)\n",
        "#print(data_2_1000.shape)\n",
        "df = pd.DataFrame(pd.np.tile(data_2, (100, 1)))\n",
        "df.columns=['A','B']\n",
        "df=df.astype(int)\n",
        "#print(df)\n",
        "#df.to_csv('data_2_1000rows.csv',index=False)\n",
        "\n",
        "\n",
        "#df = pd.read_csv(\"data_2_1000rows.csv\") # 3columns A,B,C that each contain values 0 to 1, block diagonal\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 500\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.shape)\n",
        "print(sample1_df.head())\n",
        "#sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "#print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "#sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Vector\n",
            "[0.6 0.5]\n",
            "Covariance Matrix\n",
            "[[0.24024024 0.1001001 ]\n",
            " [0.1001001  0.25025025]]\n",
            "(1000, 2)\n",
            "(500, 2)\n",
            "     A  B\n",
            "37   1  1\n",
            "726  1  1\n",
            "846  1  1\n",
            "295  1  0\n",
            "924  1  0\n",
            "     A_0  A_1  B_0  B_1\n",
            "37     0    1    0    1\n",
            "726    0    1    0    1\n",
            "846    0    1    0    1\n",
            "295    0    1    1    0\n",
            "924    0    1    1    0\n",
            "..   ...  ...  ...  ...\n",
            "194    0    1    1    0\n",
            "136    0    1    0    1\n",
            "581    1    0    1    0\n",
            "662    1    0    1    0\n",
            "671    1    0    1    0\n",
            "\n",
            "[500 rows x 4 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up-Ps6PEoQB4"
      },
      "source": [
        "P(A,B) = \r\n",
        "*   P(A=0,B=0) = 0.3\r\n",
        "*P(A=0,B=1) = 0.1\r\n",
        "*P(A=1,B=0) = 0.2\r\n",
        "*P(A=1,B=1) = 0.4\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f415a519-f371-4fe3-9561-7d211a64a92d"
      },
      "source": [
        "def groundTruth(df,query_attribute,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    \n",
        "    #q = inference.query(variables=['A','B','C'])\n",
        "    #joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=[query_attribute], evidence=evidence)\n",
        "    print(q)\n",
        "\n",
        "print('\\n P(B|A=0) Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':0})\n",
        "\n",
        "print('\\n P(A|B=0) Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':1})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " P(B|A=0) Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.7500 |\n",
            "+------+----------+\n",
            "| B(1) |   0.2500 |\n",
            "+------+----------+\n",
            "\n",
            " P(A|B=0) Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.3333 |\n",
            "+------+----------+\n",
            "| B(1) |   0.6667 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTvWAZ9UARW"
      },
      "source": [
        "# ppandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bto996MFUCnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f310fd2-1854-4eac-9fa8-ffe2bb504796"
      },
      "source": [
        "def ppandas_query(sample1_df,num_samples,query_attribute,evidence):\n",
        "    pd1 = PDataFrame(['B'],sample1_df)\n",
        "    q = pd1.query(['A','B'])\n",
        "    cols = q.columns.tolist()\n",
        "    q = q.rename(columns={q.columns[2]:'Probability(A,B)'})\n",
        "    #Reorder columns\n",
        "    q = q[['A','B','Probability(A,B)']]\n",
        "    q= q.sort_values(by=['A','B'])\n",
        "    #print(q)\n",
        "    #Sort rows in dataframe by descending order\n",
        "    print(\"\\n ppandas P({}|{}) , n={} \\n \".format(query_attribute,evidence,num_samples))\n",
        "    q1 = pd1.query([query_attribute],evidence_vars=evidence)\n",
        "    print(q1)\n",
        "    q1 = pd1.map_query([query_attribute],evidence_vars=evidence)\n",
        "    #pd_join.visualise()\n",
        "    return q1\n",
        "\n",
        "q1 = ppandas_query(sample1_df,num_samples,query_attribute='B',evidence={'A':0})\n",
        "q1 = ppandas_query(sample1_df,num_samples,query_attribute='B',evidence={'A':1})\n",
        "#print(ppandas_C)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ppandas P(B|{'A': 0}) , n=500 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.770732\n",
            "1  1.0        0.229268\n",
            "\n",
            " ppandas P(B|{'A': 1}) , n=500 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.318644\n",
            "1  1.0        0.681356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q"
      },
      "source": [
        "# Multivariate Normal\n",
        "Koller Equation 7.3: \\\\\n",
        "$P(z_A,z_B) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_A \\\\ \\mu_B \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{A} & \\Sigma_{AB} \\\\ \\Sigma_{BA} & \\Sigma_{B} \\end{array} \\right] \\right) $ \n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354) https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf: \\\\\n",
        "$P(z_A|z_B) = Normal_{z_A}(\\hat{\\mu}_A, \\hat{\\Sigma}_A)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_A = \\mu_A + \\Sigma_{AB} \\Sigma_{B}^{-1}(z_B - \\mu_B)$ \\\\\n",
        "$\\hat{\\Sigma}_A = \\Sigma_A - \\Sigma_{AB} \\Sigma_B^{-1} \\Sigma_{AB}^T$ \\\\\n",
        "\n",
        "$P(z_B|z_A) = Normal_{z_B}(\\hat{\\mu}_B, \\hat{\\Sigma}_B)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_B = \\mu_B + \\Sigma_{AB}^T \\Sigma_{A}^{-1}(z_A - \\mu_A)$ \\\\\n",
        "$\\hat{\\Sigma}_B = \\Sigma_B - \\Sigma_{AB}^T \\Sigma_A^{-1} \\Sigma_{AB}$ \\\\\n",
        "\n",
        "\n",
        "The output of the VAE encoders are assumed to be the mean and variance of the unary normal potentials in the MRF over the latent z's where:\n",
        "\n",
        "•\tMean: $\\mu_{A}$ and diagonal variance matrix: $\\Sigma_{A}$ are the outputs of the A encoder \\\\\n",
        "•\t$\\mu_{B}$,  $\\Sigma_{B}$ are the outputs of the B encoder \\\\\n",
        "\n",
        "\n",
        "The additional pairwise k-ary Normal potentials, which represent undirected graphical model structure between the latent A and latent B : \\\\\n",
        "•\t$\\Sigma_{AB}$ = $\\Sigma_{BA}^T$ \n",
        "\n",
        "If the latent space is dimension 3, each $\\mu \\in \\mathcal{R}^{1 \\times 3}$ and each $\\Sigma \\in \\mathcal{R}^{3 \\times 3}$.\n",
        "\n",
        "\n",
        "# Training the VAE-MRF\n",
        "Assuming no missing data. Training is done in two stages. The first stage learns marginal VAEs for each attribute. The second stage learns the covariance matrix $\\Sigma_{AB}$ to capture the intervariable dependencies between A and B.\n",
        "\n",
        "##Stage 1 - Marginal VAEs (Identical to Stage 1 VAEM)\n",
        "Train A and B VAEs separately.\n",
        "In each epoch, break the training data into batches. Each batch contains samples of OHE input $x_A$ or $x_B$:\n",
        "- Feed in $x_A$ or $x_B$ to their respective encoders to obtain either:\n",
        "  - $\\mu_A, \\Sigma_A$ from encoder A\n",
        "  - $\\mu_B, \\Sigma_B$ from encoder B\n",
        "\n",
        "- To reconstruct $x_A$ ($x_B$):\n",
        "  - Sample $z_A$ ($z_B$) using $\\mu_A, \\Sigma_A$ ($\\mu_B, \\Sigma_B$) through standard VAE reparameterization trick\n",
        "  - Feed $z_A$  ($z_B$) into the **A** (**B**) decoder to obtain the reconstruction $\\hat{x}_A$ ($\\hat{x}_B$)\n",
        "\n",
        "- Sum the losses (reconstruction error and KL-divergence) from either A or B  and backpropagate once per batch.\n",
        "\n",
        "For marginal VAEs, fix the parameters: encoder $\\phi$ and decoder $\\theta$.\n",
        "\n",
        "## Stage 2 - Intervariable Dependency CRF\n",
        "In each epoch, break the training data into batches. Each batch contains samples of OHE input $x_A$ and $x_B$. By reconstructing $x_A, x_B$ from $x_A$ and $x_B$, learn $\\Sigma_{AB}$:\n",
        "  - Feed entire batch of $x_A$ to marginal A encoder to obtain Monte Carlo emperical $\\mu_A, \\Sigma_A$\n",
        "  - Feed entire batch of $x_B$ to marginal B encoder to obtain Monte Carlo emperical $\\mu_B, \\Sigma_B$\n",
        "  - If memory allows - feed in entire train population of $x_A$ and $x_B$ for more reliable emperical estimates\n",
        "  - To reconstruct a specific $x_A$:\n",
        "      - Feed specific corresponding $x_B$ to marginal encoder to obtain sample $z_B$ (standard VAE reparameterization trick)\n",
        "      - Using $z_B,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_A$ from $P(z_A|z_B)$ (modified VAE reparameterization trick)\n",
        "      - Feed $z_A$ into the A decoder to obtain the reconstruction $\\hat{x}_A$\n",
        "\n",
        "  - To reconstruct $x_B$:\n",
        "    - Feed specific corresponding $x_A$ to marginal encoder to obtain sample $z_A$ (standard VAE reparameterization trick) \n",
        "    - Using $z_A,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$ (modified VAE reparameterization trick)\n",
        "    - Feed $z_B$ into the B decoder to obtain the reconstruction $\\hat{x}_B$\n",
        "\n",
        "\n",
        "Sum the losses (reconstruction error and KL-divergence) from both A and B and backpropagate once per batch.\n",
        "Repeat for each batch. \\\\\n",
        "\n",
        "Note that $\\mu_A$, $\\Sigma_A$, $\\mu_B$, $\\Sigma_B$ are fixed for each batch.  There is only one $\\Sigma_{AB}$ to be shared. \n",
        "\n",
        "# Stage 2 - Intervariable Dependency CRF (missing data at train time scenario, not implemented)\n",
        "Training the VAE-MRF on x_A only: \n",
        "- Feed entire batch of $x_A$ to marginal A encoder to obtain emperical $\\mu_A, \\Sigma_A$\n",
        "-  Feed entire batch of $x_B$ to marginal B encoder to obtain emperical $\\mu_B, \\Sigma_B$ (If no $x_B$ assume prior P(zB) = Normal (0, Identity))\n",
        "- Sample $z_B$ using $\\mu_B, \\Sigma_B$ (standard VAE reparameterization trick)\n",
        "- Using $z_B,\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_A$ from $P(z_A|z_B)$ (modified VAE reparameterization trick)\n",
        "-  Feed $z_A$ into the A decoder to obtain the reconstruction $\\hat{x}_A$ for $x_A$\n",
        "- Sum the losses (reconstruction error and KL-divergence) from A and backpropagate once per batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y"
      },
      "source": [
        "# VAE Parameters\n",
        "num = 2 # digits from 0 to 1\n",
        "latent_dims = 1 # Latent z_A, z_B same dimension size\n",
        "num_epochs = 200\n",
        "batch_size = 25\n",
        "learning_rate = 1e-3 #1e-4\n",
        "use_gpu = True\n",
        "variational_beta = 0.001 #tuned 0.001"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifSVkjMe-lJj"
      },
      "source": [
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\r\n",
        "  criterion = nn.CrossEntropyLoss()\r\n",
        "  CE = criterion(batch_recon, batch_targets)\r\n",
        "  #print(CE)\r\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\r\n",
        "  #print(KLd)\r\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd\r\n",
        "\r\n",
        "#Train marginal VAE\r\n",
        "def trainVAE(VAE, sample1_OHE, attribute: str):\r\n",
        "  print(\"\\nTraining marginal VAE for \" + attribute+ \" started!\")\r\n",
        "  VAE.train() #set model mode to train\r\n",
        "  optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\r\n",
        "  x = sample1_OHE.filter(like=attribute, axis=1).values\r\n",
        "  #sample2_OHE when do BC plate\r\n",
        "  \r\n",
        "  inds = list(range(x.shape[0]))\r\n",
        "  N = num_samples\r\n",
        "  freq = num_epochs // 10 # floor division\r\n",
        "\r\n",
        "  loss_hist = []\r\n",
        "  x = Variable(torch.from_numpy(x))\r\n",
        "  \r\n",
        "  for epoch in range(num_epochs):\r\n",
        "      #print('epoch' + str(epoch))\r\n",
        "      inds = np.random.permutation(inds)\r\n",
        "      x = x[inds]\r\n",
        "      x = x.to(device)\r\n",
        "      \r\n",
        "      loss = 0\r\n",
        "      CE = 0\r\n",
        "      KLd = 0\r\n",
        "      #num_batches = N / batch_size\r\n",
        "      for b in range(0, N, batch_size):\r\n",
        "          #get the mini-batch\r\n",
        "          x_batch = x[b: b+batch_size]\r\n",
        "          #feed forward\r\n",
        "          batch_recon,latent_mu,latent_logvar = VAE.forward(x_batch.float())\r\n",
        "          # Error\r\n",
        "          #Convert x_batch from OHE vectors to single scalar\r\n",
        "          # max returns index location of max value in each sample of batch \r\n",
        "          _, x_batch_targets = x_batch.max(dim=1)\r\n",
        "          train_CE, train_KLd, train_loss = vae_loss(batch_recon, x_batch_targets, latent_mu, latent_logvar)\r\n",
        "          loss += train_loss.item() / N # update epoch loss\r\n",
        "          CE += train_CE.item() / batch_size\r\n",
        "          KLd += train_KLd.item() / batch_size\r\n",
        "\r\n",
        "          #Backprop the error, compute the gradient\r\n",
        "          optimizer.zero_grad()\r\n",
        "          train_loss = train_loss\r\n",
        "          train_loss.backward()\r\n",
        "\r\n",
        "          #update parameters based on gradient\r\n",
        "          optimizer.step()\r\n",
        "          \r\n",
        "      #Record loss per epoch        \r\n",
        "      loss_hist.append(loss)\r\n",
        "      \r\n",
        "      if epoch % freq == 0:\r\n",
        "          print('')\r\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\r\n",
        "\r\n",
        "          #Test with all training data\r\n",
        "          VAE.eval()\r\n",
        "          train_recon, train_mu, train_logvar = VAE.forward(x.float())\r\n",
        "          _, x_targets = x.max(dim=1)\r\n",
        "          CE_,KLd,test_loss = vae_loss(train_recon, x_targets, train_mu, train_logvar)\r\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\r\n",
        "\r\n",
        "          #print('Visualize ' + attribute + 'predictions')\r\n",
        "          #print(train_recon[0:5])\r\n",
        "          #print(x_targets[0:5])\r\n",
        "\r\n",
        "  print(\"\\nTraining marginal VAE for \" + attribute+ \" finished!\")\r\n",
        "  #print(loss_hist)\r\n",
        "\r\n",
        "#Each attribute has a marginal VAE\r\n",
        "class marginal_VAE(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.latent_dims = latent_dims\r\n",
        "        self.fc1 = nn.Linear(num, latent_dims)\r\n",
        "        self.fc_mu = nn.Linear(latent_dims, latent_dims)\r\n",
        "        self.fc_logvar = nn.Linear(latent_dims, latent_dims)\r\n",
        "        self.fc_out = nn.Linear(latent_dims,num)\r\n",
        "    \r\n",
        "    #accepts OHE input of an attribute, returns mu and log variance\r\n",
        "    def encode(self, x):\r\n",
        "        h1 = torch.sigmoid(self.fc1(x))\r\n",
        "        return self.fc_mu(h1), self.fc_logvar(h1)\r\n",
        "\r\n",
        "    #Given mu and logvar generates latent z \r\n",
        "    def reparameterize(self, mu, logvar):\r\n",
        "        std = torch.exp(0.5*logvar) \r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return mu + eps*std\r\n",
        "\r\n",
        "    #Decodes latent z into reconstruction with dimension equal to num\r\n",
        "    def decode(self, z):\r\n",
        "        if z.size()[0] == self.latent_dims: #resize from [1] to [1,1]\r\n",
        "          z = z.view(1, self.latent_dims)\r\n",
        "        softmax = nn.Softmax(dim=1)  #normalizes reconstruction to range [0,1] and sum to 1\r\n",
        "        recon = softmax(self.fc_out(z))\r\n",
        "        return recon\r\n",
        "    \r\n",
        "    #Given x, returns: reconstruction x_hat, mu, log_var\r\n",
        "    def forward(self, x):\r\n",
        "        mu, logvar = self.encode(x)\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return self.decode(z), mu, logvar\r\n",
        "    \r\n",
        "    #Given x, returns latent z\r\n",
        "    def latent(self, x):\r\n",
        "        mu, logvar = self.encode(x)\r\n",
        "        z = self.reparameterize(mu, logvar)\r\n",
        "        return z\r\n",
        "    \r\n",
        "    # ignore latent_mu, latent_logvar, instead generate z values from standard normal\r\n",
        "    def sample(self, num_samples):\r\n",
        "      z = torch.randn(num_samples, self.latent_dims)\r\n",
        "      z = z.to(device)\r\n",
        "      samples = self.decode(z)\r\n",
        "      return samples"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB"
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.latent_dims = latent_dims\n",
        "        #Marginal VAEs\n",
        "        self.VAE_A = marginal_VAE()\n",
        "        self.VAE_B = marginal_VAE()\n",
        "        #Emperical mu and logvar\n",
        "        self.muA_emp = 0\n",
        "        self.muB_emp = 0\n",
        "        self.logvarA_emp = 0\n",
        "        self.logvarB_emp = 0\n",
        "        #Sigma_{AB} = Sigma_{BA}^T\n",
        "        self.covarianceAB = torch.randn(size=(self.latent_dims,self.latent_dims))\n",
        "        self.covarianceAB = torch.nn.Parameter(self.covarianceAB,requires_grad=True)\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "\n",
        "    #Stage 1 - Train Marginal VAEs and then freeze parameters\n",
        "    def train_marginals(self):\n",
        "        trainVAE(self.VAE_A,sample1_OHE, 'A')\n",
        "        trainVAE(self.VAE_B,sample1_OHE, 'B')\n",
        "\n",
        "    #Finds emperical mean and logvar of each attribute for entire population\n",
        "    def emp_mu_logvar(self,x,attribute):\n",
        "      if attribute == 'A':\n",
        "        muA, logvarA = self.encode(x, attribute)\n",
        "        self.muA_emp = torch.mean(muA,0,keepdim=True) #need to modify if muA is more than 1 dimension\n",
        "        self.logvarA_emp = torch.mean(logvarA,0,keepdim=True)\n",
        "        print('Emperical A mu and logvar')\n",
        "        print(self.muA_emp)\n",
        "        print(self.logvarA_emp)\n",
        "      elif attribute == 'B':\n",
        "        muB, logvarB = self.encode(x, attribute)\n",
        "        self.muB_emp = torch.mean(muB,0,keepdim=True)\n",
        "        self.logvarB_emp = torch.mean(logvarB,0,keepdim=True)\n",
        "        print('Emperical B mu and logvar')\n",
        "        print(self.muB_emp)\n",
        "        print(self.logvarB_emp)\n",
        "      return\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    # Attribute is the attribute of the returned z_cond \n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #log-space for numerical stability.\n",
        "        logvarA = torch.exp(0.5*logvarA)\n",
        "        logvarB = torch.exp(0.5*logvarB)\n",
        "        covarianceA = torch.diag_embed(logvarA) #Convert logvar vector to diagonal matrix\n",
        "        covarianceB = torch.diag_embed(logvarB) #batch_size,3,3\n",
        "        muA = muA.unsqueeze(2)\n",
        "        muB = muB.unsqueeze(2)\n",
        "        z = z.unsqueeze(2)\n",
        "        if attribute == 'A':\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                    torch.inverse(covarianceB)),\n",
        "                                      (z - muB)) # z is zB\n",
        "          logvar_cond = covarianceA - torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                                torch.inverse(covarianceB)),\n",
        "                                                  torch.transpose(self.covarianceAB,0,1))\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims) # regularization\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1),\n",
        "                                                    torch.inverse(covarianceA)), \n",
        "                                       (z - muA)) # z is zA\n",
        "          logvar_cond = covarianceB - torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1), \n",
        "                                                              torch.inverse(covarianceA)),\n",
        "                                                 self.covarianceAB)\n",
        "              # logvar_cond is not a diagonal covariance matrix\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims)\n",
        "\n",
        "        # METHOD1: re-parameterization trick to sample z_cond\n",
        "        eps = torch.randn_like(mu_cond) #64x3x1, 64x3x3 if use logvar_cond\n",
        "        z_cond = mu_cond + torch.matmul(logvar_cond,eps) #64x3x1\n",
        "        z_cond = z_cond.squeeze(2) #64x3\n",
        "        return z_cond\n",
        "\n",
        "    #return mu, logvar\n",
        "    def encode(self, x, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.encode(x)\n",
        "      elif attribute =='B':\n",
        "        return self.VAE_B.encode(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "    \n",
        "    #return reconstruction\n",
        "    def decode(self, z, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.decode(z)\n",
        "      elif attribute =='B':\n",
        "        return self.VAE_B.decode(z)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "    \n",
        "    #Given xA, xB and attribute to reconstruct, return reconstruction\n",
        "    def forward(self, xA, xB, attribute):\n",
        "      muA, logvarA = self.encode(xA, attribute='A') #logvar is size [64,3]\n",
        "      muB, logvarB = self.encode(xB, attribute='B')\n",
        "      # Take batch emperical average of mus and logvars\n",
        "      #size_placeholder = muA.size() #[batch_size,latent_dims]\n",
        "      #muA_emp = torch.mean(muA,0,keepdim=True).repeat(size_placeholder,1) #(batchsize,latent_dims) all repeated values of avg\n",
        "      #logvarA_emp = torch.mean(logvarA,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #muB_emp = torch.mean(muB,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #logvarB_emp = torch.mean(logvarB,0,keepdim=True).repeat(size_placeholder,1)\n",
        "      #print(logvarA)\n",
        "      if attribute == 'A':\n",
        "        zB = self.VAE_B.reparameterize(muB, logvarB)\n",
        "        zA = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zB, attribute)\n",
        "        return self.decode(zA,attribute), self.muA_emp, self.logvarA_emp #should error use emperical avg or not?\n",
        "      elif attribute == 'B':\n",
        "        zA = self.VAE_A.reparameterize(muA, logvarA)\n",
        "        zB = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zA, attribute)\n",
        "        return self.decode(zB,attribute), self.muB_emp, self.logvarB_emp\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    def latent(self,x,attribute):\n",
        "      if attribute == 'A':\n",
        "          return self.VAE_A.latent(x)\n",
        "      elif attribute == 'B':\n",
        "        return self.VAE_B.latent(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    #Given x, returns: reconstruction x_hat, mu, log_var\n",
        "    def forward_single_attribute(self, x, attribute):\n",
        "      if attribute == 'A':\n",
        "        return self.VAE_A.forward(x)\n",
        "      elif attribute == 'B':\n",
        "        return self.VAE_B.forward(x)\n",
        "      raise Exception('Invalid attribute {} provided.'.format(x))\n",
        "\n",
        "    def query_single_attribute(self, x_evidence, evidence_attribute):\n",
        "      if evidence_attribute =='A':\n",
        "        muA,logvarA = self.encode(x_evidence, evidence_attribute)\n",
        "        #muB = torch.zeros(muA.size()) #100x3\n",
        "        #logvarB = torch.ones(muA.size()) #100x3\n",
        "        zA = self.VAE_A.reparameterize(muA, logvarA)\n",
        "        #Use emperical mus and logvars\n",
        "        zB = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zA, attribute='B')\n",
        "        return self.decode(zB,attribute='B')\n",
        "\n",
        "      elif evidence_attribute =='B':\n",
        "        muB,logvarB = self.encode(x_evidence, evidence_attribute)\n",
        "        zB = self.VAE_B.reparameterize(muB, logvarB)\n",
        "        zA = self.conditional(self.muA_emp, self.logvarA_emp, self.muB_emp, self.logvarB_emp, zB, attribute='A')\n",
        "        return self.decode(zA,attribute='A')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01"
      },
      "source": [
        "def trainVAE_MRF(VAE_MRF):\n",
        "  VAE_MRF.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  #Calculate mu_emp and logvar_emp for all attributes (entire sample)\n",
        "  VAE_MRF.emp_mu_logvar(xA.float(),attribute='A')\n",
        "  VAE_MRF.emp_mu_logvar(xB.float(),attribute='B')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      #print('epoch' + str(epoch))\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "\n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward, should latent mu and logvar be the same for every recon, yes since want to learn covariance accurately?\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE_MRF.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE_MRF.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "\n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          loss += train_loss_A.item() / batch_size # update epoch loss\n",
        "          loss += train_loss_B.item() / batch_size\n",
        "          CE += train_CE_A.item() / batch_size\n",
        "          CE += train_CE_B.item() / batch_size \n",
        "          KLd += train_KLd_A.item() / batch_size\n",
        "          KLd += train_KLd_B.item() / batch_size\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print('')\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "\n",
        "          #Test with all training data\n",
        "          VAE_MRF.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE_MRF.forward(xA.float(),xB.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE_MRF.forward(xA.float(),xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_reconA, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_reconB, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining MRF finished!\")\n",
        "  #print(loss_hist)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6394f931-c0f2-45a3-9dc7-6e48d54e5583"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE_MRF = VariationalAutoencoder_MRF()\n",
        "VAE_MRF = VAE_MRF.to(device)\n",
        "\n",
        "VAE_MRF.train_marginals() #Stage 1, then freeze marginal VAEs\n",
        "print('Parameters for Marginal VAEs fixed')\n",
        "for param in VAE_MRF.VAE_A.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in VAE_MRF.VAE_B.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "num_params = sum(p.numel() for p in VAE_MRF.parameters() if p.requires_grad)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "#for param in VAE_MRF.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE_MRF.parameters()))\n",
        "#print(VAE_MRF.parameters)\n",
        "\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, VAE_MRF.parameters()), lr = learning_rate)\n",
        "print(\"CovarianceAB before training\")\n",
        "print(VAE_MRF.covarianceAB.cpu().detach().numpy())\n",
        "#num_epochs = 5000\n",
        "trainVAE_MRF(VAE_MRF)\n",
        "print(\"CovarianceAB after training\")\n",
        "print(VAE_MRF.covarianceAB.cpu().detach().numpy())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training marginal VAE for A started!\n",
            "\n",
            "Epoch 1/200\t CE: 0.60419, KLd: 0.01599, Train loss=0.03101\t\t CE: 0.60419, KLd: 0.38446, Test loss: 1.13438\n",
            "Epoch 21/200\t CE: 0.54902, KLd: 0.00399, Train loss=0.02765\t\t CE: 0.54902, KLd: 0.09651, Test loss: 0.77927\n",
            "Epoch 41/200\t CE: 0.54219, KLd: 0.00118, Train loss=0.02717\t\t CE: 0.54219, KLd: 0.02854, Test loss: 0.70561\n",
            "Epoch 61/200\t CE: 0.54224, KLd: 0.00027, Train loss=0.02713\t\t CE: 0.54224, KLd: 0.00650, Test loss: 0.68508\n",
            "Epoch 81/200\t CE: 0.53788, KLd: 0.00019, Train loss=0.02690\t\t CE: 0.53788, KLd: 0.00510, Test loss: 0.67625\n",
            "Epoch 101/200\t CE: 0.50129, KLd: 0.00251, Train loss=0.02519\t\t CE: 0.50129, KLd: 0.06634, Test loss: 0.69602\n",
            "Epoch 121/200\t CE: 0.37267, KLd: 0.01131, Train loss=0.01920\t\t CE: 0.37267, KLd: 0.28895, Test loss: 0.76353\n",
            "Epoch 141/200\t CE: 0.30524, KLd: 0.02059, Train loss=0.01629\t\t CE: 0.30524, KLd: 0.51881, Test loss: 0.90353\n",
            "Epoch 161/200\t CE: 0.27645, KLd: 0.02628, Train loss=0.01514\t\t CE: 0.27645, KLd: 0.65872, Test loss: 1.00210\n",
            "Epoch 181/200\t CE: 0.26626, KLd: 0.02833, Train loss=0.01473\t\t CE: 0.26626, KLd: 0.70859, Test loss: 1.04067\n",
            "Training marginal VAE for A finished!\n",
            "\n",
            "Training marginal VAE for B started!\n",
            "\n",
            "Epoch 1/200\t CE: 0.57990, KLd: 0.01150, Train loss=0.02957\t\t CE: 0.57990, KLd: 0.27678, Test loss: 0.97636\n",
            "Epoch 21/200\t CE: 0.55769, KLd: 0.00341, Train loss=0.02806\t\t CE: 0.55769, KLd: 0.08250, Test loss: 0.77893\n",
            "Epoch 41/200\t CE: 0.55492, KLd: 0.00088, Train loss=0.02779\t\t CE: 0.55492, KLd: 0.02106, Test loss: 0.71378\n",
            "Epoch 61/200\t CE: 0.55533, KLd: 0.00019, Train loss=0.02778\t\t CE: 0.55533, KLd: 0.00464, Test loss: 0.69836\n",
            "Epoch 81/200\t CE: 0.55473, KLd: 0.00004, Train loss=0.02774\t\t CE: 0.55473, KLd: 0.00087, Test loss: 0.69395\n",
            "Epoch 101/200\t CE: 0.55494, KLd: 0.00002, Train loss=0.02775\t\t CE: 0.55494, KLd: 0.00050, Test loss: 0.69329\n",
            "Epoch 121/200\t CE: 0.55360, KLd: 0.00004, Train loss=0.02768\t\t CE: 0.55360, KLd: 0.00101, Test loss: 0.69336\n",
            "Epoch 141/200\t CE: 0.54576, KLd: 0.00069, Train loss=0.02732\t\t CE: 0.54576, KLd: 0.01921, Test loss: 0.70113\n",
            "Epoch 161/200\t CE: 0.42989, KLd: 0.00951, Train loss=0.02197\t\t CE: 0.42989, KLd: 0.24648, Test loss: 0.77271\n",
            "Epoch 181/200\t CE: 0.30733, KLd: 0.02189, Train loss=0.01646\t\t CE: 0.30733, KLd: 0.55287, Test loss: 0.93405\n",
            "Training marginal VAE for B finished!\n",
            "Parameters for Marginal VAEs fixed\n",
            "Number of parameters: 1\n",
            "CovarianceAB before training\n",
            "[[-1.0142963]]\n",
            "Emperical A mu and logvar\n",
            "tensor([[0.1845]])\n",
            "tensor([[-1.8436]])\n",
            "Emperical B mu and logvar\n",
            "tensor([[0.1582]])\n",
            "tensor([[-1.7898]])\n",
            "\n",
            "Epoch 1/200\t CE: 1.29721, KLd: 0.00081, Train loss=1.29801\t\t CE: 1.64033, KLd: 0.00081, Test loss: 1.64134\n",
            "Epoch 21/200\t CE: 1.33146, KLd: 0.00081, Train loss=1.33227\t\t CE: 1.64989, KLd: 0.00081, Test loss: 1.65089\n",
            "Epoch 41/200\t CE: 1.31274, KLd: 0.00081, Train loss=1.31355\t\t CE: 1.65552, KLd: 0.00081, Test loss: 1.65653\n",
            "Epoch 61/200\t CE: 1.32797, KLd: 0.00081, Train loss=1.32878\t\t CE: 1.62763, KLd: 0.00081, Test loss: 1.62864\n",
            "Epoch 81/200\t CE: 1.25275, KLd: 0.00081, Train loss=1.25356\t\t CE: 1.55952, KLd: 0.00081, Test loss: 1.56053\n",
            "Epoch 101/200\t CE: 1.35743, KLd: 0.00081, Train loss=1.35823\t\t CE: 1.70970, KLd: 0.00081, Test loss: 1.71071\n",
            "Epoch 121/200\t CE: 1.26522, KLd: 0.00081, Train loss=1.26603\t\t CE: 1.58417, KLd: 0.00081, Test loss: 1.58518\n",
            "Epoch 141/200\t CE: 1.28119, KLd: 0.00081, Train loss=1.28200\t\t CE: 1.56749, KLd: 0.00081, Test loss: 1.56850\n",
            "Epoch 161/200\t CE: 1.23991, KLd: 0.00081, Train loss=1.24072\t\t CE: 1.58903, KLd: 0.00081, Test loss: 1.59004\n",
            "Epoch 181/200\t CE: 1.28107, KLd: 0.00081, Train loss=1.28188\t\t CE: 1.59941, KLd: 0.00081, Test loss: 1.60042\n",
            "Training MRF finished!\n",
            "CovarianceAB after training\n",
            "[[-1.0092436]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKa-T94O5mXH"
      },
      "source": [
        "# P(A,B) Multivariate Gaussian Ground Truth (1000 data points)\r\n",
        "## Mean: \r\n",
        "[0.6 0.5]\r\n",
        "\r\n",
        "##Covariance: \r\n",
        "\r\n",
        "[[0.24024024, 0.1001001 ]\r\n",
        "\r\n",
        "[0.1001001,  0.25025025]]\r\n",
        "\r\n",
        "# Hardcode Ground truth logvar,mu, Covariance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxjVeK606_Ub"
      },
      "source": [
        "VAE_MRF.eval()\r\n",
        "hardcode = False\r\n",
        "if hardcode == True:\r\n",
        "  with torch.no_grad():\r\n",
        "      #VAE_MRF.covarianceAB = torch.nn.Parameter(torch.tensor(0.1001001))\r\n",
        "      #VAE_MRF.covarianceAB = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(VAE_MRF.covarianceAB,0),0))\r\n",
        "      VAE_MRF.covarianceAB = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.1001001),0),0))\r\n",
        "      VAE_MRF.muA_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.6),0),0))\r\n",
        "      VAE_MRF.muB_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.5),0),0))\r\n",
        "      VAE_MRF.logvarA_emp = torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.24024024),0),0))\r\n",
        "      VAE_MRF.logvarB_emp =torch.nn.Parameter(torch.unsqueeze(torch.unsqueeze(torch.tensor(0.25025025),0),0))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkKiDijtuUHt"
      },
      "source": [
        "## Check encoder, decoders work on their own\r\n",
        "It appears the marginal VAEs converges to a local minimum with accurate reconstructions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c670195-97dc-4676-deca-06e26e66e02b"
      },
      "source": [
        "x_test = np.eye(num)[np.arange(num)]                        # Test data (one-hot encoded)\n",
        "x_test = Variable(torch.from_numpy(x_test))\n",
        "x_test = x_test.to(device)\n",
        "\n",
        "print(\"Print prediction results for A only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE_MRF.forward_single_attribute(x=x.float(), attribute='A')[0].cpu().detach().numpy(),decimals=2)))\n",
        "\n",
        "print(\"Print prediction results for B only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE_MRF.forward_single_attribute(x=x.float(), attribute='B')[0].cpu().detach().numpy(),decimals=2)))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print prediction results for A only:\n",
            "\tInput: [1. 0.] \t Output: [[0.98 0.02]]\n",
            "\tInput: [0. 1.] \t Output: [[0.02 0.98]]\n",
            "Print prediction results for B only:\n",
            "\tInput: [1. 0.] \t Output: [[0.98 0.02]]\n",
            "\tInput: [0. 1.] \t Output: [[0.05 0.95]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbLTCH8lrJe"
      },
      "source": [
        "# Visualize Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae0jQpqykvUb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c38215f2-b5aa-41df-ed69-01aef96c49b9"
      },
      "source": [
        "xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "xA = Variable(torch.from_numpy(xA))\n",
        "xB = Variable(torch.from_numpy(xB))\n",
        "\n",
        "np_zA = np.empty(0)\n",
        "for x in xA:\n",
        "  zA = VAE_MRF.latent(x.float(), attribute='A')\n",
        "  #print(z)\n",
        "  np_zA = np.concatenate((np_zA, zA.cpu().detach().numpy()))\n",
        "np_zA = np_zA.reshape(num_samples,latent_dims)\n",
        "\n",
        "if latent_dims==1:\n",
        "  plt.plot(np_zA, 'o', color='black');\n",
        "elif latent_dims ==2:\n",
        "  plt.plot(np_zA[:,0], np_zA[:,1],'o', color='black');\n",
        "elif latent_dims ==3:\n",
        "  from mpl_toolkits.mplot3d import Axes3D\n",
        "  fig = plt.figure()\n",
        "  ax = Axes3D(fig)\n",
        "  #t = np.arange(1000)\n",
        "  ax.scatter(np_zA[:,0], np_zA[:,1], np_zA[:,2])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBTljFA9YMa"
      },
      "source": [
        "# Query P(B|A=0).\n",
        "##Ground truth: \n",
        "\n",
        "P(B=0|A=0) = 0.75\n",
        "\n",
        "P(B=1|A=0) = 0.25\n",
        "\n",
        "\n",
        "Feed nothing into B encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZdoZXu9biT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e49e80-c787-41cf-d0f9-5c8454dea49c"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(10000,1)\n",
        "print('A evidence input, first 5 rows')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "\n",
        "xB_query = VAE_MRF.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 rows\n",
            "tensor([[1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.],\n",
            "        [1., 0.]], dtype=torch.float64)\n",
            "B query output:\n",
            "[[0.   1.  ]\n",
            " [0.77 0.23]\n",
            " [1.   0.  ]\n",
            " [1.   0.  ]\n",
            " [1.   0.  ]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.9459, 0.0541], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 9523, 1: 477}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQ15yUZnHsc"
      },
      "source": [
        "# Query P(B|A=1), \n",
        "## Groundtruth: \n",
        "\n",
        "P(B=0|A=1) = 1/3\n",
        "\n",
        "P(B=1|A=1) = 2/3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFsGFCqQmIZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6581cf0-df81-4c6c-943c-550ffd4b00c4"
      },
      "source": [
        "xA_evidence = x_test[1] #Evidence is A=1\n",
        "xA_evidence = xA_evidence.repeat(10000,1)\n",
        "print('A evidence input, first 5 rows')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "\n",
        "xB_query = VAE_MRF.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 rows\n",
            "tensor([[0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.],\n",
            "        [0., 1.]], dtype=torch.float64)\n",
            "B query output:\n",
            "[[0.   1.  ]\n",
            " [0.   1.  ]\n",
            " [0.   1.  ]\n",
            " [0.   1.  ]\n",
            " [0.76 0.24]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.1138, 0.8862], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1034, 1: 8966}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gVDBBLmw7u"
      },
      "source": [
        "Notice that the VAE_MRF can answer the query, but not as accurately as ppandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5whHhIl14l5"
      },
      "source": [
        "# Query P(B|A=1,B=1)\r\n",
        "Feed both A and B, correctly identifies correct B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPPraAN111xK",
        "outputId": "22030fb9-fd81-4792-99bb-a87d98e8b897"
      },
      "source": [
        "xA_evidence = x_test[1] #Evidence is A=1\r\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\r\n",
        "\r\n",
        "xB_evidence = x_test[1] #Evidence is A=1\r\n",
        "xB_evidence = xB_evidence.repeat(10000,1)\r\n",
        "\r\n",
        "xB_query,_,_ = VAE_MRF.forward(xA_evidence.float(),xB_evidence.float(), 'A')\r\n",
        "print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\r\n",
        "print(xB_query.size())\r\n",
        "\r\n",
        "#Averaging all xB_query\r\n",
        "print('xB_query mean of each column:')\r\n",
        "print(torch.mean(xB_query,0))\r\n",
        "\r\n",
        "#Taking max of each row in xB_query and counting times each element is max\r\n",
        "print('xB_query count of when each column is max:')\r\n",
        "_,indices_max =xB_query.max(dim=1) \r\n",
        "#print(indices_max.numpy())\r\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\r\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.   1.  ]\n",
            " [0.   1.  ]\n",
            " [0.97 0.03]\n",
            " [0.   1.  ]\n",
            " [0.   1.  ]]\n",
            "torch.Size([10000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.0766, 0.9234], grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 720, 1: 9280}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMp0BWBo3po"
      },
      "source": [
        "#Query P(A|B= -1)\n",
        "Try feeding into B encoder negative ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5B_9zMpBib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "981c0670-ebed-4a52-eca8-d6ea240a4be4"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "xB = torch.tensor([0,0])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,0])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,1]) # if feed in valid input, get correct result\n",
        "xB = xB.repeat(1000,1)\n",
        "\n",
        "xB_query,_,_ = VAE_MRF.forward(xA_evidence.float(),xB.float(), attribute='B')\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 2])\n",
            "xB_query mean of each column:\n",
            "tensor([0.9381, 0.0619], grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZJqFYQKqEWZ"
      },
      "source": [
        "- No matter xA evidence, if B encoder always given -1's B decoder same xB\n",
        "- No matter xA evidence, if B encoder always given 0's B decoder returns same xB\n",
        "- If feed in valid xB as evidence, then get correct xB as expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niyylLQg52C9"
      },
      "source": [
        "# Querying the VAE-MRF\r\n",
        "Once  the VAE-MRF is trained, to query P(B|A=0=(1,0,0,0,0,0,0,0))\r\n",
        "- Feed $x_A$ into the A encoder to obtain $\\mu_A, \\Sigma_A$\r\n",
        "- Sample $z_A$ using $\\mu_A, \\Sigma_A$ (standard VAE reparameterization trick)\r\n",
        "- Since no input $x_B$ to the B encoder, assume $\\mu_B, \\Sigma_B$ come from the prior P(z) = Normal (0, Identity)\r\n",
        "- Using $z_A, \\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$\r\n",
        "- Feed $z_B$ into the B decoder to obtain $\\hat{x}_B$ \\\\\r\n",
        "\r\n",
        "Repeat, feeding in evidence $x_A$ multiple times to the VAE-MRF to obtain a probability distribution $P(\\hat{x}_B|x_A)$\r\n",
        "\r\n",
        "# Extension to Two Datasets AB and BC (not yet implemented)\r\n",
        "$P(z_A,z_B,z_C) = Normal\r\n",
        "\\left(\\left( \\begin{array}{r} \\mu_A \\\\ \\mu_B \\\\ \\mu_C \\end{array} \\right), \r\n",
        "\\left[ \\begin{array}{r} \\Sigma_{A} & \\Sigma_{AB} & 0 \\\\ \\Sigma_{BA} & \\Sigma_{B} & \\Sigma_{BC}  \\\\ 0 & \\Sigma_{CB} & \\Sigma_{C} \\end{array} \\right] \\right) $ \r\n",
        "\r\n",
        "In addition to the AB VAE-MRF: \\\\\r\n",
        "  - $\\mu_{C}$,  $\\Sigma_{C}$ are the outputs of the C encoder \\\\\r\n",
        "  -\t$\\Sigma_{BC}$ = $\\Sigma_{CB}^T$ \r\n",
        "\r\n",
        "## Training the ABC VAE-MRF \r\n",
        "First sample $x_B$ from either the AB or BC dataset. Then using $x_B$, sample $x_A$ from the AB dataset and sample $x_C$ from the BC dataset.\r\n",
        "\r\n",
        "- As given previously, feed $x_A, x_B$ to their respective encoders to obtain  $\\mu_A, \\Sigma_A,  \\mu_B, \\Sigma_B$ and obtain reconstructions $\\hat{x_A}, \\hat{x_B}$. Then sum the losses (reconstruction error and KL-divergence) from both A and B  and backpropagate once per batch\r\n",
        "\r\n",
        "- Feed in $x_C$ and $x_B$ to their respective encoders to:\r\n",
        "  - obtain $\\mu_C, \\Sigma_C$ from encoder C\r\n",
        "  - obtain $\\mu_B, \\Sigma_B$ from encoder B\r\n",
        "\r\n",
        "- To reconstruct $x_C$:\r\n",
        "  - Sample $z_B$ using $\\mu_B, \\Sigma_B$ (standard VAE reparameterization trick)\r\n",
        "  - Using $z_B,\\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_C$ from $P(z_C|z_B)$ (modified VAE reparameterization trick)\r\n",
        "  - Feed $z_C$ into the C decoder to obtain the reconstruction $\\hat{x}_C$ for $x_C$\r\n",
        "\r\n",
        "- To reconstruct $x_B$:\r\n",
        "  - Sample $z_C$ using $\\mu_C, \\Sigma_C$ (standard VAE reparameterization trick)\r\n",
        "  - Using $z_C,\\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_C)$ (modified VAE reparameterization trick)\r\n",
        "  - Feed $z_B$ into the B decoder to obtain the reconstruction $\\hat{x}_B$ for $x_B$\r\n",
        "\r\n",
        "- Sum the losses (reconstruction error and KL-divergence) from both B and C  and backpropagate once per batch\r\n",
        "\r\n",
        "## Querying the ABC VAE-MRF\r\n",
        "Once  the VAE-MRF is trained, to query P(C|A=0=(1,0,0,0,0,0,0,0))\r\n",
        "- Feed $x_A$ into the A encoder to obtain $\\mu_A, \\Sigma_A$\r\n",
        "- Sample $z_A$ using $\\mu_A, \\Sigma_A$ (standard VAE reparameterization trick)\r\n",
        "- Since no input $x_B, x_C$ to the B or C encoders, assume $\\mu_B, \\Sigma_B$ and $\\mu_C, \\Sigma_C$ come from the prior P(z) = Normal (0, Identity)\r\n",
        "- Using $z_A, \\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$, sample $z_B$ from $P(z_B|z_A)$\r\n",
        "- Using $z_B, \\mu_C, \\Sigma_C, \\mu_B, \\Sigma_B$, sample $z_C$ from $P(z_C|z_B)$\r\n",
        "- Feed $z_C$ into the C decoder to obtain $\\hat{x}_C$ \\\\\r\n",
        "\r\n",
        "Repeat, feeding in evidence $x_A$ multiple times to the VAE-MRF to obtain a probability distribution $P(\\hat{x}_B|x_A)$\r\n",
        "\r\n",
        "# Notes\r\n",
        "\r\n",
        "A symmetric matrix is positive definite if:\r\n",
        "\r\n",
        "- all the diagonal entries are positive, and\r\n",
        "- each diagonal entry is greater than the sum of the absolute values of all other entries in the corresponding row/column.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPKlzMCE8abG"
      },
      "source": [
        "# Questions and Notes\n",
        "\n",
        "Requires alternating between AB and BC samples where B is the same.\n",
        "\n",
        "Have a separate plate for each dataset.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "How to handle datasets with 3 dimensions.\n",
        "Latent edges between A,B,C (clique)?\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgk-LlXB64eb"
      },
      "source": [
        "# To Do\n",
        "\n",
        "- Query P(A|B=0)\n",
        "- Add BC Plate\n",
        "- Visualize latent space\n",
        "- Try more than 1 sample when sampling zA and zB\n",
        "- During training, try reconstructing A given only x_B and reconstructing B given only x_A. I believe feeding in A (and B) to reconstruct A during train time does not match what is required of the model during test time where we feed in only B to reconstruct A.\n",
        "- Modifying variational_beta to lowest value that reconstructions were valid did not change ressults (0.0001), any higher variational_beta gave poor reconstructions.\n",
        "- Check if training on only A improves performance\n",
        "- Formalize in Overleaf\n",
        "- Answer general research questions\n",
        "- Try different likelihood functions (bernoulli, gaussian)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ_f2Kmg7H9O"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}