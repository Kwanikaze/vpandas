{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMay78wv0ZEq44zHAT7UqXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "84ddc2cf-5411-4b7b-94c3-0ed26e51d226"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "c2ab0fcf-f570-47ac-8bcf-17116a332723"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 249.93it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 403.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        # Sigma_AB is the top right term\n",
        "        self.covarianceAB = nn.Parameter(torch.randn(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #torch.distributions.multivariate_normal.MultivariateNormal(loc = [muA,muB], scale_tril = self.covarianceBA)\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar): #mu.size() = batch_size, 3\n",
        "        std = torch.exp(0.5*logvar) #batch_size,3\n",
        "        eps = torch.randn_like(std) #batch_size,3\n",
        "        return mu + eps*std # batch_size,3\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #Convert logvarA vector to diagonal matrix\n",
        "        covarianceA = torch.diag_embed(logvarA) #batch_size,3,3\n",
        "        covarianceB = torch.diag_embed(logvarB)\n",
        "        if attribute == 'A': \n",
        "          mu_cond = muA + torch.mm(torch.mm(self.covarianceAB, \n",
        "                                            torch.inverse(covarianceB)),\n",
        "                                   (z - muB)) # z is zB\n",
        "          mu_logvar = covarianceA - torch.mm(torch.mm(covarianceAB, \n",
        "                                                      torch.inverse(covarianceB)),\n",
        "                                             torch.transpose(covarianceAB,0,1))\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.mm(torch.transpose(self.covarianceAB,0,1),\n",
        "                                            torch.inverse(covarianceA), \n",
        "                                   (z - muA)) # z is zA\n",
        "          mu_logvar = covarianceB - torch.mm(torch.mm(torch.transpose(covarianceAB,0,1), \n",
        "                                                      torch.inverse(covarianceA)),\n",
        "                                             covarianceAB,0,1)\n",
        "        print(mu_logvar)\n",
        "        return reparameterize(mu_cond, mu_logvar) # mu_logvar is not a diagonal covariance matrix\n",
        "        #VAE reparameterization trick with non-diagonal covariance?\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          muA, logvarA = self.encode(x, attribute) #logvar is diagonal covariance matrix\n",
        "          #zA = self.reparameterize(muA, logvarA)\n",
        "          zA = self.conditional(muA, logvarA)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          muB, logvarB = self.encode(x, attribute)\n",
        "          #zB = self.reparameterize(muB, logvarB)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, x_batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  x_trainA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  x_targetA = x_trainA.copy()\n",
        "  x_trainB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  x_targetB = x_trainB.copy()\n",
        "  #print(x_trainA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  #x_train, x_target = generate_data(num=num)\n",
        "  indsA = list(range(x_trainA.shape[0]))\n",
        "  indsB = list(range(x_trainB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  x_trainA = Variable(torch.from_numpy(x_trainA))\n",
        "  x_targetA = Variable(torch.from_numpy(x_targetA))\n",
        "  x_trainB = Variable(torch.from_numpy(x_trainB))\n",
        "  x_targetB = Variable(torch.from_numpy(x_targetB))\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      x_trainA = x_trainA[indsA]\n",
        "      x_trainA = x_trainA.to(device)\n",
        "      x_targetA = x_targetA[indsA]\n",
        "      x_targetA = x_targetA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      x_trainB = x_trainB[indsA]\n",
        "      x_trainB = x_trainB.to(device)\n",
        "      x_targetB = x_targetB[indsA]\n",
        "      x_targetB = x_targetB.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batch = x_train[b: b+batch_size]\n",
        "          x_target_batch = x_target[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_recon,latent_mu,latent_logvar = VAE.forward(x=x_batch.float())\n",
        "          \n",
        "          # Error\n",
        "          #Convert x_batch from OHE vectors to single scalar for target class, of each sample in batch \n",
        "          _, x_batch_targets = x_batch.max(dim=1)\n",
        "          train_CE, train_KLd, train_loss = vae_loss(batch_recon, x_batch_targets, latent_mu, latent_logvar)\n",
        "          #print(batch_recon.size())\n",
        "          #print(x_batch_targets.size())\n",
        "          loss += train_loss.item() / N # update epoch loss\n",
        "          CE += train_CE.item() / N \n",
        "          KLd += train_KLd.item() / N \n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print()\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "          \n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_recon, train_mu, train_logvar = VAE(x = x_train.float(),latent_dims=latent_dims)\n",
        "          _, x_targets = x_target.max(dim=1)\n",
        "          CE,KLd,test_loss = vae_loss(train_recon, x_targets, train_mu, train_logvar)\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "outputId": "8a5e9d83-7d59-480c-fcd2-1073dd4e673e"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "for param in VAE.parameters():\n",
        "    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "#print(VAE.parameters)\n",
        "#print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 8])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([8, 3])\n",
            "<class 'torch.Tensor'> torch.Size([8])\n",
            "<class 'torch.Tensor'> torch.Size([3, 8])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([8, 3])\n",
            "<class 'torch.Tensor'> torch.Size([8])\n",
            "xtrainA\n",
            "(1000, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-5c131eb77b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrainVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-98-50d3e9be5266>\u001b[0m in \u001b[0;36mtrainVAE\u001b[0;34m(VAE)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m       \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'x_train' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 97,
      "outputs": []
    }
  ]
}