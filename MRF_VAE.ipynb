{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMwmNOBilXBVMevfE3F3ZbQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "7f0d3f30-3160-4c4b-a155-74c72acabc4e"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "e2cf1af0-843b-4426-8f10-d3fecc1aec13"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 329.66it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 409.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        self.covarianceAB = nn.Parameter(torch.randn(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def conditional(self, mu, logvar, attribute):\n",
        "        if attribute == 'A':\n",
        "          std = torch.exp(0.5*logvar)\n",
        "          eps = torch.randn_like(std)\n",
        "          return mu + eps*std\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          muA, logvarA = self.encode(x, attribute)\n",
        "          #zA = self.reparameterize(muA, logvarA)\n",
        "          zA = self.conditional(muA, logvarA)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          muB, logvarB = self.encode(x, attribute)\n",
        "          #zB = self.reparameterize(muB, logvarB)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, x_batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  x_target = sample1_OHE.copy()\n",
        "  x_trainA = sample1_OHE.filter(like='A', axis=1)\n",
        "  x_trainB = sample1_OHE.filter(like='B', axis=1)\n",
        "  print(x_trainA)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  #x_train, x_target = generate_data(num=num)\n",
        "  inds = list(range(x_train.shape[0]))\n",
        "  N = x_train.shape[0] # 800\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  x_train = Variable(torch.from_numpy(x_train))\n",
        "  x_target = Variable(torch.from_numpy(x_target))\n",
        "  for epoch in range(num_epochs):\n",
        "      inds = np.random.permutation(inds)\n",
        "      x_train = x_train[inds]\n",
        "      x_train = x_train.to(device)\n",
        "      x_target = x_target[inds]\n",
        "      x_target = x_target.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batch = x_train[b: b+batch_size]\n",
        "          x_target_batch = x_target[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_recon,latent_mu,latent_logvar = VAE.forward(x=x_batch.float())\n",
        "          \n",
        "          # Error\n",
        "          #Convert x_batch from OHE vectors to single scalar for target class, of each sample in batch \n",
        "          _, x_batch_targets = x_batch.max(dim=1)\n",
        "          train_CE, train_KLd, train_loss = vae_loss(batch_recon, x_batch_targets, latent_mu, latent_logvar)\n",
        "          #print(batch_recon.size())\n",
        "          #print(x_batch_targets.size())\n",
        "          loss += train_loss.item() / N # update epoch loss\n",
        "          CE += train_CE.item() / N \n",
        "          KLd += train_KLd.item() / N \n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print()\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "          \n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_recon, train_mu, train_logvar = VAE(x = x_train.float(),latent_dims=latent_dims)\n",
        "          _, x_targets = x_target.max(dim=1)\n",
        "          CE,KLd,test_loss = vae_loss(train_recon, x_targets, train_mu, train_logvar)\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")\n",
        "\n",
        "  #delete"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "outputId": "43ed98bd-d6e7-44e9-c54a-07d9af1e5b18"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "for param in VAE.parameters():\n",
        "    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "#print(VAE.parameters)\n",
        "#print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 8])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([8, 3])\n",
            "<class 'torch.Tensor'> torch.Size([8])\n",
            "<class 'torch.Tensor'> torch.Size([3, 8])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([3, 3])\n",
            "<class 'torch.Tensor'> torch.Size([3])\n",
            "<class 'torch.Tensor'> torch.Size([8, 3])\n",
            "<class 'torch.Tensor'> torch.Size([8])\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  A_7\n",
            "4333    0    0    0    0    0    0    0    1\n",
            "2638    0    0    0    0    0    0    1    0\n",
            "2254    0    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0    0\n",
            "604     1    0    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 8 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5c131eb77b11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrainVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-72-38c4c6a5f10a>\u001b[0m in \u001b[0;36mtrainVAE\u001b[0;34m(VAE)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m#x_train, x_target = generate_data(num=num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mfreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;31m# floor division\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'x_train' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 73,
      "outputs": []
    }
  ]
}