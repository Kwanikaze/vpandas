{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOAibyJk0/xrNJeBoZLmnFH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "886b4564-ffe1-40c2-f1ed-3061da399239"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "98f79188-c259-49d9-b46c-c7d7109e004d"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 396.92it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 434.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        # Sigma_AB is the top right term\n",
        "        #self.covarianceAB = nn.Parameter(torch.zeros(latent_dims,latent_dims),requires_grad=True)\n",
        "        #self.covarianceAB = torch.randn(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        self.covarianceAB = torch.randn(size=(latent_dims,latent_dims))\n",
        "        #print(self.covarianceAB)\n",
        "        #print(torch.inverse(self.covarianceAB))\n",
        "        self.covarianceAB = torch.nn.Parameter(self.covarianceAB,requires_grad=True)\n",
        "        #self.covarianceAB = nn.Parameter(torch.rand(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar): #mu.size() = batch_size, 3\n",
        "        std = torch.exp(0.5*logvar) #batch_size,3  ,3\n",
        "        eps = torch.randn_like(std) #want batch_size,3 not #batch_size,3,3\n",
        "        print('mu,std,eps size')\n",
        "        print(mu.size())\n",
        "        print(std.size())\n",
        "        print(eps.size())\n",
        "        return mu + eps*std # batch_size,3\n",
        "\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #Convert logvarA vector to diagonal matrix\n",
        "        logvarA = torch.exp(0.5*logvarA)\n",
        "        logvarB = torch.exp(0.5*logvarB)\n",
        "        covarianceA = torch.diag_embed(logvarA) #batch_size,3,3\n",
        "        covarianceB = torch.diag_embed(logvarB)\n",
        "        #self.covarianceAB = torch.nn.Parameter(0.5* torch.exp(self.covarianceAB),requires_grad=True)\n",
        "        print(self.covarianceAB)\n",
        "        print('covarianceA')\n",
        "        print(covarianceA)\n",
        "        muA = muA.unsqueeze(2)\n",
        "        muB = muB.unsqueeze(2)\n",
        "        z = z.unsqueeze(2)\n",
        "        if attribute == 'A':\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                    torch.inverse(covarianceB)),\n",
        "                                   (z - muB)) # z is zB\n",
        "          logvar_cond = covarianceA - torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                      torch.inverse(covarianceB)),\n",
        "                                             torch.transpose(self.covarianceAB,0,1))\n",
        "          logvar_cond = logvar_cond + 100*torch.eye(latent_dims)\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1),\n",
        "                                                    torch.inverse(covarianceA)), \n",
        "                                       (z - muA)) # z is zA\n",
        "          logvar_cond = covarianceB - torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1), \n",
        "                                                              torch.inverse(covarianceA)),\n",
        "                                                 self.covarianceAB)\n",
        "          logvar_cond = logvar_cond + 100*torch.eye(latent_dims)\n",
        "        print('mu_cond, logvar_cond size')\n",
        "        mu_cond = mu_cond.squeeze(2)\n",
        "        print(mu_cond.size()) # 64x3x1\n",
        "        print(mu_cond)\n",
        "        print(logvar_cond.size()) #64x3x3\n",
        "        print(logvar_cond)\n",
        "        distrib = MultivariateNormal(loc=mu_cond, covariance_matrix=logvar_cond)\n",
        "        sample = distrib.rsample()\n",
        "        print('Multivariate Normal size')\n",
        "        print(sample.size())\n",
        "        return sample\n",
        "        #return self.reparameterize(mu_cond, logvar_cond) # logvar_cond is not a diagonal covariance matrix\n",
        "        #VAE reparameterization trick with non-diagonal covariance?\n",
        "        #https://stats.stackexchange.com/questions/388620/variational-autoencoder-and-covariance-matrix\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, xA, xB, attribute):\n",
        "        muA, logvarA = self.encode(xA, attribute='A') #logvar is size [64,3]\n",
        "        muB, logvarB = self.encode(xB, attribute='B')\n",
        "        if attribute == 'A':\n",
        "          zB = self.reparameterize(muB, logvarB)\n",
        "          print('zB size')\n",
        "          print(zB.size())\n",
        "          zA = self.conditional(muA, logvarA, muB, logvarB, zB, attribute)\n",
        "          print('zA size')\n",
        "          print(zA.size())\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  print('batch_targets, batch_recon size')\n",
        "  print(batch_targets.size())\n",
        "  print(batch_recon.size())\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354).\n",
        "\n",
        "A symmetric matrix is positive definite if:\n",
        "\n",
        "- all the diagonal entries are positive, and\n",
        "- each diagonal entry is greater than the sum of the absolute values of all other entries in the corresponding row/column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "      print('epoch' + str(epoch))\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "          print('batch_recon size')\n",
        "          print(batch_reconA.size())\n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          #print(batch_reconA.size())\n",
        "          #print(xA_batch_targets.size())\n",
        "          loss += train_loss_A.item() / N # update epoch loss\n",
        "          loss += train_loss_B.item() / N\n",
        "          CE += train_CE_A.item() / N\n",
        "          CE += train_CE_B.item() / N \n",
        "          KLd += train_KLd_A.item() / N\n",
        "          KLd += train_KLd_B.item() / N\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print()\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "          \n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE.forward(xA.float(),xB.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE.forward(xA.float(),xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_reconA, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_reconB, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "f940bc8b-0192-4771-f916-cab6495f5151"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "#for param in VAE.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "#print(VAE.parameters)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-94bf7db3eedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Focus on just AB Plate for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#  use gpu if available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mVAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariationalAutoencoder_MRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mVAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}