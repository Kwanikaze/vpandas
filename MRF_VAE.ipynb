{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMBWaD2sLWMj7F2hvEps2/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "cd3aacef-829b-44d1-cb49-032166eff0f2"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "outputId": "e069f7f9-d3b1-47a0-853d-9004966cf53b"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 527.12it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 241.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        # Sigma_AB is the top right term\n",
        "        self.covarianceAB = nn.Parameter(torch.randn(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #torch.distributions.multivariate_normal.MultivariateNormal(loc = [muA,muB], scale_tril = self.covarianceBA)\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar): #mu.size() = batch_size, 3\n",
        "        std = torch.exp(0.5*logvar) #batch_size,3\n",
        "        eps = torch.randn_like(std) #batch_size,3\n",
        "        return mu + eps*std # batch_size,3\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #Convert logvarA vector to diagonal matrix\n",
        "        covarianceA = torch.diag_embed(logvarA) #batch_size,3,3\n",
        "        covarianceB = torch.diag_embed(logvarB)\n",
        "        if attribute == 'A':\n",
        "          print(self.covarianceAB.size())\n",
        "          print(covarianceB.size())\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                            torch.inverse(covarianceB)),\n",
        "                                   (z - muB)) # z is zB\n",
        "          mu_logvar = covarianceA - torch.matmul(torch.matmul(covarianceAB, \n",
        "                                                      torch.inverse(covarianceB)),\n",
        "                                             torch.transpose(covarianceAB,0,1))\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.mm(torch.transpose(self.covarianceAB,0,1),\n",
        "                                            torch.inverse(covarianceA), \n",
        "                                   (z - muA)) # z is zA\n",
        "          mu_logvar = covarianceB - torch.mm(torch.mm(torch.transpose(covarianceAB,0,1), \n",
        "                                                      torch.inverse(covarianceA)),\n",
        "                                             covarianceAB,0,1)\n",
        "        #print(mu_logvar)\n",
        "        return reparameterize(mu_cond, mu_logvar) # mu_logvar is not a diagonal covariance matrix\n",
        "        #VAE reparameterization trick with non-diagonal covariance?\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, xA, xB, attribute):\n",
        "        muA, logvarA = self.encode(xA, attribute='A') #logvar is diagonal covariance matrix\n",
        "        muB, logvarB = self.encode(xB, attribute='B')\n",
        "        if attribute == 'A':\n",
        "          zB = self.reparameterize(muB, logvarB)\n",
        "          zA = self.conditional(muA, logvarA, muB, logvarB, zB, attribute)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, x_batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "          \n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          #print(batch_reconA.size())\n",
        "          #print(xA_batch_targets.size())\n",
        "          loss += train_loss_A.item() / N # update epoch loss\n",
        "          loss += train_loss_B.item() / N\n",
        "          CE += train_CE_A.item() / N\n",
        "          CE += train_CE_B.item() / N \n",
        "          KLd += train_KLd_A.item() / N\n",
        "          KLd += train_KLd_B.item() / N\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print()\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "          \n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE.forward(x = xA.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE.forward(x = xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_recon_A, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_recon_B, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4159fc4a-f7bd-43ae-984a-fe5f6b7637bc"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "#for param in VAE.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "#print(VAE.parameters)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 175\n",
            "torch.Size([3, 3])\n",
            "torch.Size([64, 3, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-94bf7db3eedd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrainVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-b051988e432e>\u001b[0m in \u001b[0;36mtrainVAE\u001b[0;34m(VAE)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0;31m#feed forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0mbatch_reconA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_muA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_logvarA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batchA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batchB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m           \u001b[0mbatch_reconB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_muB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_logvarB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batchA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batchB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-04911a455b49>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, xA, xB, attribute)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0mzB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvarB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0mzA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmuA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvarA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmuB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvarB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmuA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvarA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-04911a455b49>\u001b[0m in \u001b[0;36mconditional\u001b[0;34m(self, muA, logvarA, muB, logvarB, z, attribute)\u001b[0m\n\u001b[1;32m     34\u001b[0m           mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n\u001b[1;32m     35\u001b[0m                                             torch.inverse(covarianceB)),\n\u001b[0;32m---> 36\u001b[0;31m                                    (z - muB)) # z is zB\n\u001b[0m\u001b[1;32m     37\u001b[0m           mu_logvar = covarianceA - torch.matmul(torch.matmul(covarianceAB, \n\u001b[1;32m     38\u001b[0m                                                       torch.inverse(covarianceB)),\n",
            "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [192 x 3], m2: [64 x 3] at /pytorch/aten/src/TH/generic/THTensorMath.cpp:41"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}