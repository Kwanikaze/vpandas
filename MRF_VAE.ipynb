{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [
        "tvSWt2iUw9xE"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNp0IEj210lxH1J4rU4y7ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "133ec250-1c0f-4b87-fef4-3e7b8a1f3ee6"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "1fe43d8d-c9c8-459c-dede-fdabc101e4fc"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pgmpy==0.1.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/b1/18dfdfcb10dcce71fd39f8c6801407e9aebd953939682558a5317e4a021c/pgmpy-0.1.9-py3-none-any.whl (331kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pgmpy\n",
            "Successfully installed pgmpy-0.1.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 214.18it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 369.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        self.covarianceAB = torch.Tensor([latent_dims,latent_dims], requires_grad = True)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B'\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          muA, logvarA = self.encode(x, attribute)\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          muB, logvarB = self.encode(x, attribute)\n",
        "          zB = self.reparameterize(muB, logvarB)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, x_batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE, latent_dims):\n",
        "  VAE.train() #set model mode to train\n",
        "  x_train = sample1_OHE\n",
        "  x_target = sample1_OHE.copy()\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  #x_train, x_target = generate_data(num=num)\n",
        "  inds = list(range(x_train.shape[0]))\n",
        "  N = x_train.shape[0] # 800\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  x_train = Variable(torch.from_numpy(x_train))\n",
        "  x_target = Variable(torch.from_numpy(x_target))\n",
        "  for epoch in range(num_epochs):\n",
        "      inds = np.random.permutation(inds)\n",
        "      x_train = x_train[inds]\n",
        "      x_train = x_train.to(device)\n",
        "      x_target = x_target[inds]\n",
        "      x_target = x_target.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batch = x_train[b: b+batch_size]\n",
        "          x_target_batch = x_target[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_recon,latent_mu,latent_logvar = VAE.forward(x=x_batch.float())\n",
        "          \n",
        "          # Error\n",
        "          #Convert x_batch from OHE vectors to single scalar for target class, of each sample in batch \n",
        "          _, x_batch_targets = x_batch.max(dim=1)\n",
        "          train_CE, train_KLd, train_loss = vae_loss(batch_recon, x_batch_targets, latent_mu, latent_logvar)\n",
        "          #print(batch_recon.size())\n",
        "          #print(x_batch_targets.size())\n",
        "          loss += train_loss.item() / N # update epoch loss\n",
        "          CE += train_CE.item() / N \n",
        "          KLd += train_KLd.item() / N \n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          print()\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "          \n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_recon, train_mu, train_logvar = VAE(x = x_train.float(),latent_dims=latent_dims)\n",
        "          _, x_targets = x_target.max(dim=1)\n",
        "          CE,KLd,test_loss = vae_loss(train_recon, x_targets, train_mu, train_logvar)\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "e7d97961-3c5c-4390-dd49-d2f50c9e45a6"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "print(VAE.parameters)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE, latent_dims=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of VariationalAutoencoder(\n",
            "  (fc1): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (fc_mu): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_logvar): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_out): Linear(in_features=3, out_features=8, bias=True)\n",
            ")>\n",
            "Number of parameters: 83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b23d19a97fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrainVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-cf33599c3c59>\u001b[0m in \u001b[0;36mtrainVAE\u001b[0;34m(VAE, latent_dims)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0minds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 800\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}