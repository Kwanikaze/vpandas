{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYHgDeeye3Q/IRimHwVegn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "06d9d708-8c82-4de5-ca96-2348839dd509"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "!pip install -i https://test.pypi.org/simple/ PPandas==0.0.1.7.1\n",
        "!pip install python-intervals\n",
        "!pip install geopandas\n",
        "!pip install geovoronoi\n",
        "import ppandas\n",
        "from ppandas import PDataFrame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: PPandas==0.0.1.7.1 in /usr/local/lib/python3.6/dist-packages (0.0.1.7.1)\n",
            "Requirement already satisfied: python-intervals in /usr/local/lib/python3.6/dist-packages (1.10.0.post1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13.post1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.6.1.post1)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: geovoronoi in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.4.1)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.7.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "fac02704-aab8-4b0d-863d-94d228a9ad2f"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbad583b-907f-490b-ac49-4d82cab969fa"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,query_attribute,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    \n",
        "    #q = inference.query(variables=['A','B','C'])\n",
        "    #joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=[query_attribute], evidence=evidence)\n",
        "    print(q)\n",
        "\n",
        "print('\\n P(B|A=0) \\n Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':0})\n",
        "\n",
        "print('\\n P(A|B=0) \\n Ground Truth')\n",
        "groundTruth(df,query_attribute = 'A', evidence = {'B':0})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "\n",
            " P(B|A=0) \n",
            " Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 750.99it/s]\n",
            "Eliminating: C: 100%|██████████| 1/1 [00:00<00:00, 297.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(7) |   0.0000 |\n",
            "+------+----------+\n",
            "\n",
            " P(A|B=0) \n",
            " Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 244.82it/s]\n",
            "Eliminating: C: 100%|██████████| 1/1 [00:00<00:00, 629.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| A    |   phi(A) |\n",
            "+======+==========+\n",
            "| A(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTvWAZ9UARW",
        "colab_type": "text"
      },
      "source": [
        "# ppandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bto996MFUCnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "39a5aef5-c607-40d1-928f-f154febe256b"
      },
      "source": [
        "\n",
        "\n",
        "def ppandas_query(sample1_df,sample2_df,num_samples,query_attribute,evidence):\n",
        "    pd1 = PDataFrame(['B'],sample1_df)\n",
        "    pd2 = PDataFrame(['B'],sample2_df)\n",
        "    pd_join = pd1.pjoin(pd2)\n",
        "    q = pd_join.query(['A','B','C'])\n",
        "    #print(\"\\n ppandas P(A,B,C) , n={} \\n \".format(num_samples))\n",
        "    #Re-arrange columns from CBA to ABC\n",
        "    cols = q.columns.tolist()\n",
        "    #print('the cols')\n",
        "    #print(cols)\n",
        "    #4th column rename to Probabability(A,B,C)\n",
        "    q = q.rename(columns={q.columns[3]:'Probability(A,B,C)'})\n",
        "    #Reorder columns\n",
        "    q = q[['A','B','C','Probability(A,B,C)']]\n",
        "    q= q.sort_values(by=['A','B','C'])\n",
        "    #print(q)\n",
        "    #Sort rows in dataframe by descending order\n",
        "    joint_prob_ppandas = q\n",
        "    #joint_prob_ppandas = q.values.flatten()[3::4] #start at 4th value(index 3), stepsize is 4\n",
        "    #print('joint')\n",
        "    #print(joint_prob_ppandas)\n",
        "    print(\"\\n ppandas P({}|{}) , n={} \\n \".format(query_attribute,evidence,num_samples))\n",
        "    q1 = pd_join.query([query_attribute],evidence_vars=evidence)\n",
        "    print(q1)\n",
        "    q1 = pd_join.map_query([query_attribute],evidence_vars=evidence)\n",
        "    query_C_result = -1\n",
        "    for _,value in q1.items():\n",
        "        query_C_result = value\n",
        "    #pd_join.visualise()\n",
        "    return joint_prob_ppandas,query_C_result\n",
        "\n",
        "\n",
        "joint_prob_ppandas, ppandas_C = ppandas_query(sample1_df,sample2_df,num_samples,query_attribute='B',evidence={'A':0})\n",
        "#print(ppandas_C)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ppandas P(B|{'A': 0}) , n=1000 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.290909\n",
            "1  1.0        0.218182\n",
            "2  2.0        0.236364\n",
            "3  3.0        0.254545\n",
            "4  4.0        0.000000\n",
            "5  5.0        0.000000\n",
            "6  6.0        0.000000\n",
            "7  7.0        0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned 0.00001"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "df4f63c7-bbf9-4dbc-9e41-ec46c29039f1"
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        # Sigma_AB is the top right term\n",
        "        #self.covarianceAB = nn.Parameter(torch.zeros(latent_dims,latent_dims),requires_grad=True)\n",
        "        self.covarianceAB = torch.randn(size=(latent_dims,latent_dims))\n",
        "        self.covarianceAB = torch.nn.Parameter(self.covarianceAB,requires_grad=True)\n",
        "        #self.covarianceAB = torch.nn.Parameter(0.5* torch.exp(self.covarianceAB),requires_grad=True)\n",
        "        #self.covarianceAB = nn.Parameter(torch.rand(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar): #mu.size() = batch_size, 3\n",
        "        std = torch.exp(0.5*logvar) #batch_size,3 \n",
        "        eps = torch.randn_like(std) #batch_size,3\n",
        "        return mu + eps*std # batch_size,3\n",
        "\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #Convert logvarA vector to diagonal matrix\n",
        "        #log-space for numerical stability.\n",
        "        logvarA = torch.exp(0.5*logvarA)\n",
        "        logvarB = torch.exp(0.5*logvarB)\n",
        "        covarianceA = torch.diag_embed(logvarA) #batch_size,3,3\n",
        "        covarianceB = torch.diag_embed(logvarB)\n",
        "        #self.covarianceAB = torch.nn.Parameter(0.5* torch.exp(self.covarianceAB),requires_grad=True)\n",
        "        muA = muA.unsqueeze(2)\n",
        "        muB = muB.unsqueeze(2)\n",
        "        z = z.unsqueeze(2)\n",
        "        if attribute == 'A':\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                    torch.inverse(covarianceB)),\n",
        "                                   (z - muB)) # z is zB\n",
        "          logvar_cond = covarianceA - torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                      torch.inverse(covarianceB)),\n",
        "                                             torch.transpose(self.covarianceAB,0,1))\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims) # regularization\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1),\n",
        "                                                    torch.inverse(covarianceA)), \n",
        "                                       (z - muA)) # z is zA\n",
        "          logvar_cond = covarianceB - torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1), \n",
        "                                                              torch.inverse(covarianceA)),\n",
        "                                                 self.covarianceAB)\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims)\n",
        "\n",
        "        # METHOD1: re-parameterization trick\n",
        "        eps = torch.randn_like(mu_cond) #64x3x1, 64x3x3 if use logvar_cond\n",
        "        sample = mu_cond + torch.matmul(logvar_cond,eps) #64x3x1\n",
        "        sample = sample.squeeze(2) #64x3\n",
        "\n",
        "        #METHOD 2 - random sampling, can't backprop\n",
        "        #mu_cond = mu_cond.squeeze(2)\n",
        "        #distrib = MultivariateNormal(loc=mu_cond, covariance_matrix=logvar_cond)\n",
        "        #sample = distrib.rsample() # 64x3\n",
        "        \n",
        "        return sample\n",
        "        # logvar_cond is not a diagonal covariance matrix\n",
        "        #VAE reparameterization trick with non-diagonal covariance?\n",
        "        #https://stats.stackexchange.com/questions/388620/variational-autoencoder-and-covariance-matrix\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, xA, xB, attribute):\n",
        "        muA, logvarA = self.encode(xA, attribute='A') #logvar is size [64,3]\n",
        "        #print(muA.size())\n",
        "        muB, logvarB = self.encode(xB, attribute='B')\n",
        "        if attribute == 'A':\n",
        "          zB = self.reparameterize(muB, logvarB)\n",
        "          zA = self.conditional(muA, logvarA, muB, logvarB, zB, attribute)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def forward_single_attribute(self, x, attribute):\n",
        "        mu, logvar = self.encode(x,attribute)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z, attribute), mu, logvar\n",
        "\n",
        "    def query_single_attribute(self, x_evidence, evidence_attribute):\n",
        "        if evidence_attribute =='A':\n",
        "          muA,logvarA = self.encode(x_evidence, evidence_attribute)\n",
        "          muB = torch.zeros(muA.size()) #100x3\n",
        "          logvarB = torch.ones(muA.size()) #100x3\n",
        "          #logvarB = torch.zeros(muA.size())\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute='B')\n",
        "          return self.decode(zB,attribute='B')\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4d2610683b5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVariationalAutoencoder_MRF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "# Multivariate Normal\n",
        "Koller Equation 7.3: \\\\\n",
        "$P(z_A,z_B) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_A \\\\ \\mu_B \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{A} & \\Sigma_{AB} \\\\ \\Sigma_{BA} & \\Sigma_{B} \\end{array} \\right] \\right) $ \n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354) https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf: \\\\\n",
        "$P(z_A|z_B) = Normal_{z_A}(\\hat{\\mu}_A, \\hat{\\Sigma}_A)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_A = \\mu_A + \\Sigma_{AB} \\Sigma_{B}^{-1}(z_B - \\mu_B)$ \\\\\n",
        "$\\hat{\\Sigma}_A = \\Sigma_A - \\Sigma_{AB} \\Sigma_B^{-1} \\Sigma_{AB}^T$ \\\\\n",
        "\n",
        "$P(z_B|z_A) = Normal_{z_B}(\\hat{\\mu}_B, \\hat{\\Sigma}_B)$ \\\\\n",
        "where: \\\\\n",
        "$\\hat{\\mu}_B = \\mu_B + \\Sigma_{AB}^T \\Sigma_{A}^{-1}(z_A - \\mu_A)$ \\\\\n",
        "$\\hat{\\Sigma}_B = \\Sigma_B - \\Sigma_{AB}^T \\Sigma_A^{-1} \\Sigma_{AB}$ \\\\\n",
        "\n",
        "\n",
        "The output of the VAE encoders are assumed to be the mean and variance of the unary normal potentials in the MRF over the latent z's where:\n",
        "\n",
        "•\tMean: $\\mu_{A}$ and diagonal variance matrix: $\\Sigma_{A}$ are the outputs of the A encoder \\\\\n",
        "•\t$\\mu_{B}$,  $\\Sigma_{B}$ are the outputs of the B encoder \\\\\n",
        "\n",
        "\n",
        "The additional pairwise k-ary Normal potentials, which represent undirected graphical model structure between the latent A and latent B : \\\\\n",
        "•\t$\\Sigma_{AB}$ = $\\Sigma_{BA}^T$ \n",
        "\n",
        "If the latent space is dimension 3, each $\\mu \\in \\mathcal{R}^{1 \\times 3}$ and each $\\Sigma \\in \\mathcal{R}^{3 \\times 3}$.\n",
        "\n",
        "# Training the VAE-MRF\n",
        "In each epoch, break the training data into batches of OHE input $x_A$ and $x_B$:\n",
        "- Feed in $x_A$ and $x_B$ to their respective encoders to:\n",
        "  - obtain $\\mu_A, \\Sigma_A$ from encoder A\n",
        "  - obtain $\\mu_B, \\Sigma_B$ from encoder B\n",
        "- To reconstruct $x_A$:\n",
        "  - Sample $z_B$ using $\\mu_B, \\Sigma_B$ (standard VAE reparameterization trick)\n",
        "  - Then using $z_B$, sample $z_A$ from $P(z_A|z_B)$ using $\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$ as well (modified VAE reparameterization trick)\n",
        "  - Feed $z_A$ into the A decoder to obtain the reconstruction $\\hat{x}_A$ for $x_A$\n",
        "\n",
        "- To reconstruct $x_B$:\n",
        "  - Sample $z_A$ using $\\mu_A, \\Sigma_A$ (standard VAE reparameterization trick)\n",
        "  - Then using $z_A$, sample $z_B$ from $P(z_B|z_A)$ using $\\mu_A, \\Sigma_A, \\mu_B, \\Sigma_B$ as well (modified VAE reparameterization trick)\n",
        "  - Feed $z_B$ into the B decoder to obtain the reconstruction $\\hat{x}_B$ for $x_B$\n",
        "\n",
        "- Sum the losses (reconstruction error and KL-divergence) from both A and B  and backpropagate once per batch\n",
        "\n",
        "Repeat for each batch. \\\\\n",
        "\n",
        "Note that there is a different $\\mu_A$, $\\Sigma_A$ for each $x_A$ and a different $\\mu_B$, $\\Sigma_B$ for each $x_B$, while there is only one $\\Sigma_{AB}$ to be shared. \n",
        "# Querying the VAE-MRF\n",
        "Once  the VAE-MRF is trained, to query P(B|A=0=(1,0,0,0,0,0,0,0))\n",
        "- Feed $x_A$ into the A encoder to obtain $\\mu_A, \\Sigma_A$ and sample to obtain z_A\n",
        "- Since no input $x_B$ to the B encoder, I assume $\\mu_B, \\Sigma_B$ come from the prior P(z) = Normal (0, Identity)\n",
        "- Using $\\mu_A, \\Sigma_A, z_A, \\mu_B, \\Sigma_B$, sample $z_B$ \n",
        "- Feed $z_B$ into the B decoder to obtain $\\hat{x}_B$ \\\\\n",
        "\n",
        "Repeat, feeding in evidence $x_A$ multiple times to the VAE-MRF to obtain a probability distribution $P(\\hat{x}_B|x_A)$\n",
        "# Notes\n",
        "\n",
        "A symmetric matrix is positive definite if:\n",
        "\n",
        "- all the diagonal entries are positive, and\n",
        "- each diagonal entry is greater than the sum of the absolute values of all other entries in the corresponding row/column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "      #print('epoch' + str(epoch))\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "\n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          loss += train_loss_A.item() / N # update epoch loss\n",
        "          loss += train_loss_B.item() / N\n",
        "          CE += train_CE_A.item() / N\n",
        "          CE += train_CE_B.item() / N \n",
        "          KLd += train_KLd_A.item() / N\n",
        "          KLd += train_KLd_B.item() / N\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          #print(VAE.covarianceAB)\n",
        "          print('')\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "\n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE.forward(xA.float(),xB.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE.forward(xA.float(),xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_reconA, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_reconB, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")\n",
        "  #print(loss_hist)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c5ca3d38-cacb-4d3f-86ea-a079b8828d6f"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "#for param in VAE.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "print(VAE.parameters)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of VariationalAutoencoder_MRF(\n",
            "  (fc1A): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (fc_muA): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_logvarA): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_outA): Linear(in_features=3, out_features=8, bias=True)\n",
            "  (fc1B): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (fc_muB): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_logvarB): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_outB): Linear(in_features=3, out_features=8, bias=True)\n",
            ")>\n",
            "Number of parameters: 175\n",
            "\n",
            "Epoch 1/1000\t CE: 0.06726, KLd: 0.00001, Train loss=0.06727\t\t CE: 4.21200, KLd: 0.00001, Test loss: 4.21964\n",
            "Epoch 101/1000\t CE: 0.05887, KLd: 0.00007, Train loss=0.05894\t\t CE: 3.66864, KLd: 0.00007, Test loss: 3.74037\n",
            "Epoch 201/1000\t CE: 0.04676, KLd: 0.00021, Train loss=0.04697\t\t CE: 2.91975, KLd: 0.00021, Test loss: 3.12877\n",
            "Epoch 301/1000\t CE: 0.04130, KLd: 0.00037, Train loss=0.04166\t\t CE: 2.57969, KLd: 0.00037, Test loss: 2.94707\n",
            "Epoch 401/1000\t CE: 0.04091, KLd: 0.00036, Train loss=0.04127\t\t CE: 2.55672, KLd: 0.00036, Test loss: 2.91500\n",
            "Epoch 501/1000\t CE: 0.04084, KLd: 0.00030, Train loss=0.04114\t\t CE: 2.55226, KLd: 0.00030, Test loss: 2.85622\n",
            "Epoch 601/1000\t CE: 0.04081, KLd: 0.00025, Train loss=0.04106\t\t CE: 2.55102, KLd: 0.00025, Test loss: 2.79845\n",
            "Epoch 701/1000\t CE: 0.04081, KLd: 0.00020, Train loss=0.04101\t\t CE: 2.55036, KLd: 0.00020, Test loss: 2.75324\n",
            "Epoch 801/1000\t CE: 0.04080, KLd: 0.00016, Train loss=0.04096\t\t CE: 2.54980, KLd: 0.00016, Test loss: 2.71408\n",
            "Epoch 901/1000\t CE: 0.04079, KLd: 0.00014, Train loss=0.04092\t\t CE: 2.54908, KLd: 0.00014, Test loss: 2.68555\n",
            "Training finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2a2hqTvnhHK",
        "colab_type": "text"
      },
      "source": [
        "It appears the model converges to a local minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkKiDijtuUHt",
        "colab_type": "text"
      },
      "source": [
        "## Check encoder, decoders work on their own\n",
        "- could also train encoder and decoders on their own?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "73562ca6-4a0b-4987-f760-bc3e1d0dc1f3"
      },
      "source": [
        "x_test = np.eye(num)[np.arange(num)]                        # Test data (one-hot encoded)\n",
        "x_test = Variable(torch.from_numpy(x_test))\n",
        "x_test = x_test.to(device)\n",
        "\n",
        "print(\"Print prediction results for A only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE.forward_single_attribute(x=x.float(), attribute='A')[0].cpu().detach().numpy(),decimals=2)))\n",
        "print(\"Print prediction results for B only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE.forward_single_attribute(x=x.float(), attribute='B')[0].cpu().detach().numpy(),decimals=2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print prediction results for A only:\n",
            "\tInput: [1. 0. 0. 0. 0. 0. 0. 0.] \t Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 1. 0. 0. 0. 0. 0. 0.] \t Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 1. 0. 0. 0. 0. 0.] \t Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 1. 0. 0. 0. 0.] \t Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 1. 0. 0. 0.] \t Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 1. 0. 0.] \t Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 1. 0.] \t Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 0. 1.] \t Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Print prediction results for B only:\n",
            "\tInput: [1. 0. 0. 0. 0. 0. 0. 0.] \t Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 1. 0. 0. 0. 0. 0. 0.] \t Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 1. 0. 0. 0. 0. 0.] \t Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 1. 0. 0. 0. 0.] \t Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 1. 0. 0. 0.] \t Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 1. 0. 0.] \t Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 1. 0.] \t Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 0. 1.] \t Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBTljFA9YMa",
        "colab_type": "text"
      },
      "source": [
        "# Query P(B|A=0)\n",
        "Feed nothing into B encoder, muB is zero, logVarB is standard diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZdoZXu9biT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "48b31679-75a9-4e08-bfb7-24f154c8eec5"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "print('A evidence input, first 5 of 100 samples:')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "xB_query = VAE.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "#print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 of 100 samples:\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "B query output:\n",
            "torch.Size([1000, 8])\n",
            "xB_query mean of each column:\n",
            "tensor([0.1222, 0.1679, 0.1000, 0.0983, 0.1340, 0.1719, 0.1270, 0.0787],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 123, 1: 166, 2: 101, 3: 102, 4: 136, 5: 171, 6: 124, 7: 77}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8gVDBBLmw7u",
        "colab_type": "text"
      },
      "source": [
        " Seems 1,4,5,6 have higher probability, which does not match ground truth or ppandas (0,1,2,3 equal prob of 0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gQ15yUZnHsc",
        "colab_type": "text"
      },
      "source": [
        "# Query P(B|A=7)\n",
        "Feed nothing into B encoder, muB is zero, logVarB is standard diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFsGFCqQmIZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8bad3e7c-0343-48e5-8b00-fdec87b954e7"
      },
      "source": [
        "xA_evidence = x_test[7] #Evidence is A=7\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "print('A evidence input, first 5 of 100 samples:')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "xB_query = VAE.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "#print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 of 100 samples:\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 1.]], dtype=torch.float64)\n",
            "B query output:\n",
            "torch.Size([1000, 8])\n",
            "xB_query mean of each column:\n",
            "tensor([0.1222, 0.1669, 0.0992, 0.1043, 0.1742, 0.1507, 0.1000, 0.0825],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 123, 1: 170, 2: 94, 3: 106, 4: 181, 5: 150, 6: 97, 7: 79}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gai-mGEZk9a5",
        "colab_type": "text"
      },
      "source": [
        "Again, Seems 1,4,5 have higher probability, which does not match ground truth or ppandas (4,5,6,7 equal prob of 0.25). Implies that the covarianceAB matrix does not have much effect compared to the standard mean + covariance prior of P(zB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oMp0BWBo3po",
        "colab_type": "text"
      },
      "source": [
        "#Query P(B|A=0)\n",
        "Try feeding into B encoder negative ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN5B_9zMpBib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a82979e3-7246-49c9-d59d-457b1cd11182"
      },
      "source": [
        "xA_evidence = x_test[7] #Evidence is A=0 or 7\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "xB = torch.tensor([-1,-1,-1,-1,-1,-1,-1,-1])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,0])\n",
        "#xB = torch.tensor([0,0,0,0,0,0,0,1]) # if feed in \n",
        "xB = xB.repeat(1000,1)\n",
        "\n",
        "xB_query,_,_ = VAE.forward(xA_evidence.float(),xB.float(), attribute='B')\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 8])\n",
            "xB_query mean of each column:\n",
            "tensor([5.5261e-14, 1.3906e-05, 3.7077e-16, 5.9777e-06, 6.2760e-08, 5.6236e-01,\n",
            "        1.1942e-12, 4.3762e-01], grad_fn=<MeanBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZJqFYQKqEWZ",
        "colab_type": "text"
      },
      "source": [
        "- No matter xA evidence, if B encoder always given -1's B decoder same xB\n",
        "- No matter xA evidence, if B encoder always given 0's B decoder returns same xB\n",
        "- If feed in valid xB as evidence, then get correct xB as expected"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84c1RN_oylrp",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing Latent Space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfWeNfaUykVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPKlzMCE8abG",
        "colab_type": "text"
      },
      "source": [
        "# Questions and Notes\n",
        "\n",
        "Requires alternating between AB and BC samples where B is the same.\n",
        "\n",
        "Have a separate plate for each dataset.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgk-LlXB64eb",
        "colab_type": "text"
      },
      "source": [
        "# To Do\n",
        "\n",
        "- Query P(A|B=0)\n",
        "- Add BC Plate\n",
        "- Visualize latent space\n",
        "- Try more than 1 sample when sampling zA and zB\n",
        "- During training, try reconstructing A given only x_B and reconstructing B given only x_A. I believe feeding in A (and B) to reconstruct A during train time does not match what is required of the model during test time where we feed in only B to reconstruct A.\n",
        "- Modifying variational_beta to lowest value that reconstructions were valid did not change ressults (0.0001), any higher variational_beta gave poor reconstructions.\n",
        "- Check if training on only A improves performance\n",
        "- Formalize in Overleaf\n",
        "- Answer general research questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ_f2Kmg7H9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    }
  ]
}