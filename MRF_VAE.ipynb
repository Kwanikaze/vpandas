{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP83NySovJQuDdzHSBsooGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "3b237597-5084-4a66-f275-74d58cdc7c2d"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "!pip install -i https://test.pypi.org/simple/ PPandas==0.0.1.7.1\n",
        "!pip install python-intervals\n",
        "!pip install geopandas\n",
        "!pip install geovoronoi\n",
        "import ppandas\n",
        "from ppandas import PDataFrame"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://test.pypi.org/simple/\n",
            "Requirement already satisfied: PPandas==0.0.1.7.1 in /usr/local/lib/python3.6/dist-packages (0.0.1.7.1)\n",
            "Requirement already satisfied: python-intervals in /usr/local/lib/python3.6/dist-packages (1.10.0.post1)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.6/dist-packages (0.8.1)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.0)\n",
            "Requirement already satisfied: pyproj>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (2.6.1.post1)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Requirement already satisfied: fiona in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.8.13.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (0.5.0)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (2.5.0)\n",
            "Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied: click-plugins>=1.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (19.3.0)\n",
            "Requirement already satisfied: geovoronoi in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.4.1)\n",
            "Requirement already satisfied: shapely>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.7.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from geovoronoi) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "1a44c66b-35b8-4524-8a62-3cb919f1e72b"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "#Could add noise so not exactly OHE: 0.01...0.9...0.01\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0ce9d27-7ad1-4d7f-95ce-e13b17532cf8"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,query_attribute,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    \n",
        "    #q = inference.query(variables=['A','B','C'])\n",
        "    #joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=[query_attribute], evidence=evidence)\n",
        "    print(q)\n",
        "\n",
        "print('\\n P(B|A=0) \\n Ground Truth')\n",
        "groundTruth(df,query_attribute = 'B', evidence = {'A':0})\n",
        "\n",
        "print('\\n P(A|B=0) \\n Ground Truth')\n",
        "groundTruth(df,query_attribute = 'A', evidence = {'B':0})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n",
            "\n",
            " P(B|A=0) \n",
            " Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 226.49it/s]\n",
            "Eliminating: C: 100%|██████████| 1/1 [00:00<00:00, 470.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| B    |   phi(B) |\n",
            "+======+==========+\n",
            "| B(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| B(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| B(7) |   0.0000 |\n",
            "+------+----------+\n",
            "\n",
            " P(A|B=0) \n",
            " Ground Truth\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 191.64it/s]\n",
            "Eliminating: C: 100%|██████████| 1/1 [00:00<00:00, 524.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "+------+----------+\n",
            "| A    |   phi(A) |\n",
            "+======+==========+\n",
            "| A(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| A(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| A(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bTvWAZ9UARW",
        "colab_type": "text"
      },
      "source": [
        "# ppandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bto996MFUCnN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "ef5189a3-9f44-4b7a-f2a8-218ab28bdce0"
      },
      "source": [
        "\n",
        "\n",
        "def ppandas_query(sample1_df,sample2_df,num_samples,query_attribute,evidence):\n",
        "    pd1 = PDataFrame(['B'],sample1_df)\n",
        "    pd2 = PDataFrame(['B'],sample2_df)\n",
        "    pd_join = pd1.pjoin(pd2)\n",
        "    q = pd_join.query(['A','B','C'])\n",
        "    #print(\"\\n ppandas P(A,B,C) , n={} \\n \".format(num_samples))\n",
        "    #Re-arrange columns from CBA to ABC\n",
        "    cols = q.columns.tolist()\n",
        "    #print('the cols')\n",
        "    #print(cols)\n",
        "    #4th column rename to Probabability(A,B,C)\n",
        "    q = q.rename(columns={q.columns[3]:'Probability(A,B,C)'})\n",
        "    #Reorder columns\n",
        "    q = q[['A','B','C','Probability(A,B,C)']]\n",
        "    q= q.sort_values(by=['A','B','C'])\n",
        "    #print(q)\n",
        "    #Sort rows in dataframe by descending order\n",
        "    joint_prob_ppandas = q\n",
        "    #joint_prob_ppandas = q.values.flatten()[3::4] #start at 4th value(index 3), stepsize is 4\n",
        "    #print('joint')\n",
        "    #print(joint_prob_ppandas)\n",
        "    print(\"\\n ppandas P({}|{}) , n={} \\n \".format(query_attribute,evidence,num_samples))\n",
        "    q1 = pd_join.query([query_attribute],evidence_vars=evidence)\n",
        "    print(q1)\n",
        "    q1 = pd_join.map_query([query_attribute],evidence_vars=evidence)\n",
        "    query_C_result = -1\n",
        "    for _,value in q1.items():\n",
        "        query_C_result = value\n",
        "    #pd_join.visualise()\n",
        "    return joint_prob_ppandas,query_C_result\n",
        "\n",
        "\n",
        "joint_prob_ppandas, ppandas_C = ppandas_query(sample1_df,sample2_df,num_samples,query_attribute='B',evidence={'A':0})\n",
        "#print(ppandas_C)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " ppandas P(B|{'A': 0}) , n=1000 \n",
            " \n",
            "     B  Probability(B)\n",
            "0  0.0        0.290909\n",
            "1  1.0        0.218182\n",
            "2  2.0        0.236364\n",
            "3  3.0        0.254545\n",
            "4  4.0        0.000000\n",
            "5  5.0        0.000000\n",
            "6  6.0        0.000000\n",
            "7  7.0        0.000000\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "num = 8 # digits from 0 to 7\n",
        "latent_dims = 3 # Latent z_A,z_B,z_C all are all same dimension size\n",
        "num_epochs = 1000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder_MRF(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc1A = nn.Linear(num, latent_dims)\n",
        "        self.fc_muA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarA = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outA = nn.Linear(latent_dims,num)\n",
        "        \n",
        "        self.fc1B = nn.Linear(num, latent_dims)\n",
        "        self.fc_muB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvarB = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_outB = nn.Linear(latent_dims,num)\n",
        "\n",
        "        #Covariance: Sigma_{AB} = Sigma_{BA}^T\n",
        "        # Sigma_AB is the top right term\n",
        "        #self.covarianceAB = nn.Parameter(torch.zeros(latent_dims,latent_dims),requires_grad=True)\n",
        "        self.covarianceAB = torch.randn(size=(latent_dims,latent_dims))\n",
        "        self.covarianceAB = torch.nn.Parameter(self.covarianceAB,requires_grad=True)\n",
        "        #self.covarianceAB = torch.nn.Parameter(0.5* torch.exp(self.covarianceAB),requires_grad=True)\n",
        "        #self.covarianceAB = nn.Parameter(torch.rand(size=(latent_dims,latent_dims), requires_grad=True))\n",
        "        #print(self.covarianceAB)\n",
        "\n",
        "    def reparameterize(self, mu, logvar): #mu.size() = batch_size, 3\n",
        "        std = torch.exp(0.5*logvar) #batch_size,3 \n",
        "        eps = torch.randn_like(std) #batch_size,3\n",
        "        return mu + eps*std # batch_size,3\n",
        "\n",
        "\n",
        "    # Conditional of Multivariate Gaussian: matrix cookbook 353 and 354\n",
        "    def conditional(self, muA, logvarA, muB, logvarB, z, attribute):\n",
        "        #Convert logvarA vector to diagonal matrix\n",
        "        logvarA = torch.exp(0.5*logvarA)\n",
        "        logvarB = torch.exp(0.5*logvarB)\n",
        "        covarianceA = torch.diag_embed(logvarA) #batch_size,3,3\n",
        "        covarianceB = torch.diag_embed(logvarB)\n",
        "        #self.covarianceAB = torch.nn.Parameter(0.5* torch.exp(self.covarianceAB),requires_grad=True)\n",
        "        muA = muA.unsqueeze(2)\n",
        "        muB = muB.unsqueeze(2)\n",
        "        z = z.unsqueeze(2)\n",
        "        if attribute == 'A':\n",
        "          mu_cond = muA + torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                    torch.inverse(covarianceB)),\n",
        "                                   (z - muB)) # z is zB\n",
        "          logvar_cond = covarianceA - torch.matmul(torch.matmul(self.covarianceAB, \n",
        "                                                      torch.inverse(covarianceB)),\n",
        "                                             torch.transpose(self.covarianceAB,0,1))\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims) # regularization\n",
        "        elif attribute == 'B':\n",
        "          mu_cond = muB + torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1),\n",
        "                                                    torch.inverse(covarianceA)), \n",
        "                                       (z - muA)) # z is zA\n",
        "          logvar_cond = covarianceB - torch.matmul(torch.matmul(torch.transpose(self.covarianceAB,0,1), \n",
        "                                                              torch.inverse(covarianceA)),\n",
        "                                                 self.covarianceAB)\n",
        "          #logvar_cond = logvar_cond + 20*torch.eye(latent_dims)\n",
        "\n",
        "        # METHOD1: re-parameterization trick\n",
        "        eps = torch.randn_like(mu_cond) #64x3x1, 64x3x3 if use logvar_cond\n",
        "        sample = mu_cond + torch.matmul(logvar_cond,eps)\n",
        "        sample = sample.squeeze(2) #64x3\n",
        "\n",
        "        #METHOD 2 - random sampling, can't backprop\n",
        "        #mu_cond = mu_cond.squeeze(2)\n",
        "        #distrib = MultivariateNormal(loc=mu_cond, covariance_matrix=logvar_cond)\n",
        "        #sample = distrib.rsample() # 64x3\n",
        "        \n",
        "        return sample\n",
        "        # logvar_cond is not a diagonal covariance matrix\n",
        "        #VAE reparameterization trick with non-diagonal covariance?\n",
        "        #https://stats.stackexchange.com/questions/388620/variational-autoencoder-and-covariance-matrix\n",
        "\n",
        "    def encode(self, x, attribute):\n",
        "        if attribute == 'A':\n",
        "          h1 = torch.sigmoid(self.fc1A(x))\n",
        "          return self.fc_muA(h1), self.fc_logvarA(h1)\n",
        "        elif attribute == 'B':\n",
        "          h1 = torch.sigmoid(self.fc1B(x))\n",
        "          return self.fc_muB(h1), self.fc_logvarB(h1)\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def decode(self, z, attribute):\n",
        "        if z.size()[0] == latent_dims: #resize from [3] to [1,3] if fed only a single sample\n",
        "            z = z.view(1, latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        if attribute == 'A':\n",
        "          reconA = softmax(self.fc_outA(z))\n",
        "          return reconA\n",
        "        elif attribute == 'B':\n",
        "          reconB = softmax(self.fc_outB(z))\n",
        "          return reconB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "    \n",
        "    def forward(self, xA, xB, attribute):\n",
        "        muA, logvarA = self.encode(xA, attribute='A') #logvar is size [64,3]\n",
        "        #print(muA.size())\n",
        "        muB, logvarB = self.encode(xB, attribute='B')\n",
        "        if attribute == 'A':\n",
        "          zB = self.reparameterize(muB, logvarB)\n",
        "          zA = self.conditional(muA, logvarA, muB, logvarB, zB, attribute)\n",
        "          return self.decode(zA,attribute), muA, logvarA\n",
        "        elif attribute == 'B':\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute)\n",
        "          return self.decode(zB,attribute), muB, logvarB\n",
        "        print('ERROR')\n",
        "        return -100\n",
        "\n",
        "    def forward_single_attribute(self, x, attribute):\n",
        "        mu, logvar = self.encode(x,attribute)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z, attribute), mu, logvar\n",
        "\n",
        "    def query_single_attribute(self, x_evidence, evidence_attribute):\n",
        "        if evidence_attribute =='A':\n",
        "          muA,logvarA = self.encode(x_evidence, evidence_attribute)\n",
        "          muB = torch.zeros(muA.size()) #100x3\n",
        "          logvarB = torch.ones(muA.size()) #100x3\n",
        "          zA = self.reparameterize(muA, logvarA)\n",
        "          zB = self.conditional(muA, logvarA, muB, logvarB, zA, attribute='B')\n",
        "          return self.decode(zB,attribute='B')\n",
        "\n",
        "def vae_loss(batch_recon, batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1Re5YHgVF-q",
        "colab_type": "text"
      },
      "source": [
        "Koller Equation 7.3: \\\\\n",
        "$P(X,Y) = Normal\n",
        "\\left(\\left( \\begin{array}{r} \\mu_X \\\\ \\mu_Y \\end{array} \\right), \n",
        "\\left[ \\begin{array}{r} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array} \\right] \\right) $ \n",
        "\n",
        "From Koller Theorem 7.4: \\\\\n",
        "$P(Y|X) = Normal (\\beta_0 + \\beta^TX, \\sigma^2)$ \\\\\n",
        "such that \\\\\n",
        "$\\beta_0 = \\mu_Y - \\Sigma_{YX} \\Sigma^{-1}_{XX}\\mu_X$ \\\\\n",
        "$\\beta = \\Sigma^{-1}_{XX} \\Sigma_{YX}$ \\\\\n",
        "$\\sigma^2 = \\Sigma_{YY} - \\Sigma_{YX}\\Sigma^{-1}_{XX}\\Sigma_{XY}$\n",
        "\n",
        "which is equivalent to the Matrix Cookbook (353 and 354).\n",
        "\n",
        "A symmetric matrix is positive definite if:\n",
        "\n",
        "- all the diagonal entries are positive, and\n",
        "- each diagonal entry is greater than the sum of the absolute values of all other entries in the corresponding row/column.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_7LH-GQRW01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainVAE(VAE):\n",
        "  VAE.train() #set model mode to train\n",
        "  xA = sample1_OHE.filter(like='A', axis=1).values\n",
        "  xB = sample1_OHE.filter(like='B', axis=1).values\n",
        "  #print(xA.shape)\n",
        "\n",
        "  #sample2_OHE when do BC plate\n",
        "  \n",
        "  indsA = list(range(xA.shape[0]))\n",
        "  indsB = list(range(xB.shape[0]))\n",
        "  N = num_samples # 1000\n",
        "  freq = num_epochs // 10 # floor division\n",
        "\n",
        "  loss_hist = []\n",
        "  xA = Variable(torch.from_numpy(xA))\n",
        "  xB = Variable(torch.from_numpy(xB))\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "      #print('epoch' + str(epoch))\n",
        "      indsA = np.random.permutation(indsA)\n",
        "      xA = xA[indsA]\n",
        "      xA = xA.to(device)\n",
        "      indsB = np.random.permutation(indsB)\n",
        "      xB = xB[indsB]\n",
        "      xB = xB.to(device)\n",
        "      \n",
        "      loss = 0\n",
        "      CE = 0\n",
        "      KLd = 0\n",
        "      num_batches = N / batch_size\n",
        "      for b in range(0, N, batch_size):\n",
        "          #get the mini-batch\n",
        "          x_batchA = xA[b: b+batch_size]\n",
        "          x_batchB = xB[b: b+batch_size]\n",
        "          \n",
        "          #feed forward\n",
        "          batch_reconA,latent_muA,latent_logvarA = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='A')\n",
        "          batch_reconB,latent_muB,latent_logvarB = VAE.forward(x_batchA.float(),x_batchB.float(),attribute='B')\n",
        "\n",
        "          # Error\n",
        "          #Convert x_batchA and x_batchB from OHE vectors to single scalar\n",
        "          # max returns index location of max value in each sample of batch \n",
        "          _, xA_batch_targets = x_batchA.max(dim=1)\n",
        "          _, xB_batch_targets = x_batchB.max(dim=1)\n",
        "          train_CE_A, train_KLd_A, train_loss_A = vae_loss(batch_reconA, xA_batch_targets, latent_muA, latent_logvarA)\n",
        "          train_CE_B, train_KLd_B, train_loss_B = vae_loss(batch_reconB, xB_batch_targets, latent_muB, latent_logvarB)\n",
        "          loss += train_loss_A.item() / N # update epoch loss\n",
        "          loss += train_loss_B.item() / N\n",
        "          CE += train_CE_A.item() / N\n",
        "          CE += train_CE_B.item() / N \n",
        "          KLd += train_KLd_A.item() / N\n",
        "          KLd += train_KLd_B.item() / N\n",
        "\n",
        "          #Backprop the error, compute the gradient\n",
        "          optimizer.zero_grad()\n",
        "          train_loss = train_loss_A + train_loss_B\n",
        "          train_loss.backward()\n",
        "          \n",
        "          #update parameters based on gradient\n",
        "          optimizer.step()\n",
        "          \n",
        "      #Record loss per epoch        \n",
        "      loss_hist.append(loss)\n",
        "      \n",
        "      if epoch % freq == 0:\n",
        "          #print(VAE.covarianceAB)\n",
        "          print('')\n",
        "          print(\"Epoch %d/%d\\t CE: %.5f, KLd: %.5f, Train loss=%.5f\" % (epoch + 1, num_epochs,CE,KLd, loss), end='\\t', flush=True)\n",
        "\n",
        "          #Test with all training data\n",
        "          VAE.eval()\n",
        "          train_reconA, train_muA, train_logvarA = VAE.forward(xA.float(),xB.float(), attribute='A')\n",
        "          train_reconB, train_muB, train_logvarB = VAE.forward(xA.float(),xB.float(), attribute='B')\n",
        "          _, xA_targets = xA.max(dim=1)\n",
        "          _, xB_targets = xB.max(dim=1)\n",
        "          CE_A,KLd_A,test_loss_A = vae_loss(train_reconA, xA_targets, train_muA, train_logvarA)\n",
        "          CE_B,KLd_B,test_loss_B = vae_loss(train_reconB, xB_targets, train_muB, train_logvarB)\n",
        "\n",
        "          CE = CE_A + CE_B\n",
        "          Kld = KLd_A + KLd_B\n",
        "          test_loss = test_loss_A + test_loss_B\n",
        "          print(\"\\t CE: {:.5f}, KLd: {:.5f}, Test loss: {:.5f}\".format(CE,KLd,test_loss.item()), end='')\n",
        "      \n",
        "  print(\"\\nTraining finished!\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples where B is the same. What if B is not the same in both datasets? How to train?\n",
        "\n",
        "Have a separate plate for each.\n",
        "In Bayesian network, need to learn P(B),P(A|B), P(C|B). \\\\\n",
        "In MRF need to learn factors $\\phi(A,B)$ and $\\phi(B,C)$.\n",
        "\n",
        "We want to query P(C|A), therefore at test time there will be no input to the B encoder.\n",
        "\n",
        "Do we need to incorporate the parition function Z? If want probabilities that sum to 1 then yes. But if just looking to have input into the decoders then normalizing isn't necessary?\n",
        "\n",
        "Koller Definition 4.3: \\\\\n",
        "$Z = \\sum_{AB,BC} \\phi(A,B) \\times \\phi(B,C)$ \\\\\n",
        "$P(A,B,C) = \\frac{1}{Z} \\phi(A,B) \\times \\phi(B,C)$ \n",
        "\n",
        "To learn $\\phi(A,B)$ where X = A and Y=B, need to re-construct A and B, have separate loss terms for the A decoder and the B decoder and backpropogate to learn the mean vectors, variance matrices and covariance matrices.\n",
        "\n",
        "Need to work in log-space for numerical stability.\n",
        "\n",
        "Assume the A encoder outputs $\\mu_A, \\Sigma_{AA}$ and the B encoder outputs $\\mu_B, \\Sigma_{BB}$.\n",
        "\n",
        "The latent variables have structure by learning $\\Sigma_{AB}, \\Sigma_{BA} = \\Sigma_{AB}^T$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "255eccef-ab90-4898-9198-3e929efeab35"
      },
      "source": [
        "# Focus on just AB Plate for now\n",
        "#  use gpu if available\n",
        "device = torch.device(\"cuda:0\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "VAE = VariationalAutoencoder_MRF()\n",
        "VAE = VAE.to(device)\n",
        "num_params = sum(p.numel() for p in VAE.parameters() if p.requires_grad)\n",
        "\n",
        "#for param in VAE.parameters():\n",
        "#    print(type(param.data), param.size())\n",
        "#print(list(VAE.parameters()))\n",
        "print(VAE.parameters)\n",
        "print(\"Number of parameters: %d\" % num_params) #8*3 + 3 = 27, 3*8 + 8 = 32 3*3+3 = 12 *2 = 24, 27+32+24=83\n",
        "\n",
        "# optimizer object\n",
        "optimizer = torch.optim.Adam(params = VAE.parameters(), lr = learning_rate)\n",
        "\n",
        "trainVAE(VAE)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.parameters of VariationalAutoencoder_MRF(\n",
            "  (fc1A): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (fc_muA): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_logvarA): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_outA): Linear(in_features=3, out_features=8, bias=True)\n",
            "  (fc1B): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (fc_muB): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_logvarB): Linear(in_features=3, out_features=3, bias=True)\n",
            "  (fc_outB): Linear(in_features=3, out_features=8, bias=True)\n",
            ")>\n",
            "Number of parameters: 175\n",
            "\n",
            "Epoch 1/1000\t CE: 0.06754, KLd: 0.00000, Train loss=0.06754\t\t CE: 4.19940, KLd: 0.00000, Test loss: 4.20267\n",
            "Epoch 101/1000\t CE: 0.05873, KLd: 0.00007, Train loss=0.05879\t\t CE: 3.66778, KLd: 0.00007, Test loss: 3.73322\n",
            "Epoch 201/1000\t CE: 0.04989, KLd: 0.00016, Train loss=0.05004\t\t CE: 3.11099, KLd: 0.00016, Test loss: 3.26953\n",
            "Epoch 301/1000\t CE: 0.04276, KLd: 0.00033, Train loss=0.04308\t\t CE: 2.66664, KLd: 0.00033, Test loss: 2.99324\n",
            "Epoch 401/1000\t CE: 0.04106, KLd: 0.00041, Train loss=0.04146\t\t CE: 2.56587, KLd: 0.00041, Test loss: 2.97129\n",
            "Epoch 501/1000\t CE: 0.04088, KLd: 0.00037, Train loss=0.04126\t\t CE: 2.55499, KLd: 0.00037, Test loss: 2.92668\n",
            "Epoch 601/1000\t CE: 0.04084, KLd: 0.00030, Train loss=0.04114\t\t CE: 2.55231, KLd: 0.00030, Test loss: 2.85467\n",
            "Epoch 701/1000\t CE: 0.04081, KLd: 0.00024, Train loss=0.04105\t\t CE: 2.55097, KLd: 0.00024, Test loss: 2.78763\n",
            "Epoch 801/1000\t CE: 0.04080, KLd: 0.00019, Train loss=0.04099\t\t CE: 2.55016, KLd: 0.00019, Test loss: 2.74307\n",
            "Epoch 901/1000\t CE: 0.04079, KLd: 0.00016, Train loss=0.04096\t\t CE: 2.54960, KLd: 0.00016, Test loss: 2.71170\n",
            "Training finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkKiDijtuUHt",
        "colab_type": "text"
      },
      "source": [
        "## Check encoder, decoders work on their own\n",
        "- could also train encoder and decoders on their own?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqYmOIxeZvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "6ecba1ea-1521-4897-9df3-733803b1c31c"
      },
      "source": [
        "x_test = np.eye(num)[np.arange(num)]                        # Test data (one-hot encoded)\n",
        "x_test = Variable(torch.from_numpy(x_test))\n",
        "x_test = x_test.to(device)\n",
        "\n",
        "print(\"Print prediction results for A only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE.forward_single_attribute(x=x.float(), attribute='A')[0].cpu().detach().numpy(),decimals=2)))\n",
        "print(\"Print prediction results for B only:\")\n",
        "for x in x_test:\n",
        "    print(\"\\tInput: {} \\t Output: {}\".format(x.cpu().detach().numpy(), np.round(VAE.forward_single_attribute(x=x.float(), attribute='B')[0].cpu().detach().numpy(),decimals=2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print prediction results for A only:\n",
            "\tInput: [1. 0. 0. 0. 0. 0. 0. 0.] \t Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 1. 0. 0. 0. 0. 0. 0.] \t Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 1. 0. 0. 0. 0. 0.] \t Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 1. 0. 0. 0. 0.] \t Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 1. 0. 0. 0.] \t Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 1. 0. 0.] \t Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 1. 0.] \t Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 0. 1.] \t Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n",
            "Print prediction results for B only:\n",
            "\tInput: [1. 0. 0. 0. 0. 0. 0. 0.] \t Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 1. 0. 0. 0. 0. 0. 0.] \t Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 1. 0. 0. 0. 0. 0.] \t Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 1. 0. 0. 0. 0.] \t Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 1. 0. 0. 0.] \t Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 1. 0. 0.] \t Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 1. 0.] \t Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "\tInput: [0. 0. 0. 0. 0. 0. 0. 1.] \t Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vBTljFA9YMa",
        "colab_type": "text"
      },
      "source": [
        "# Query P(B|A=0)\n",
        "Feed nothing into B encoder, muB is zero, logVarB is standard diagonal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZdoZXu9biT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7f120c68-beaf-4e47-c48e-2317962c1e16"
      },
      "source": [
        "xA_evidence = x_test[0] #Evidence is A=0\n",
        "xA_evidence = xA_evidence.repeat(1000,1)\n",
        "print('A evidence input, first 5 of 100 samples:')\n",
        "print(xA_evidence[0:5]) #need to resize/ view for single sample, or make evidence a batch repeated\n",
        "\n",
        "print('B query output:')\n",
        "xB_query = VAE.query_single_attribute(x_evidence=xA_evidence.float(), evidence_attribute = 'A')\n",
        "#print(np.round(xB_query[0:5].cpu().detach().numpy(),decimals=2))\n",
        "print(xB_query.size())\n",
        "#Averaging all xB_query\n",
        "print('xB_query mean of each column:')\n",
        "print(torch.mean(xB_query,0))\n",
        "\n",
        "\n",
        "#Taking max of each row in xB_query and counting times each element is max\n",
        "print('xB_query count of when each column is max:')\n",
        "_,indices_max =xB_query.max(dim=1) \n",
        "#print(indices_max.numpy())\n",
        "unique, counts = np.unique(indices_max.numpy(), return_counts=True)\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A evidence input, first 5 of 100 samples:\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
            "B query output:\n",
            "torch.Size([1000, 8])\n",
            "xB_query mean of each column:\n",
            "tensor([0.0641, 0.1401, 0.1456, 0.0992, 0.1023, 0.1975, 0.1556, 0.0956],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "xB_query count of when each column is max:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 57, 1: 141, 2: 146, 3: 94, 4: 105, 5: 201, 6: 154, 7: 102}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gai-mGEZk9a5",
        "colab_type": "text"
      },
      "source": [
        "Seems 1,2,5,6 have higher probability, which does not match ground truth or ppandas (0,1,2,3 equal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgk-LlXB64eb",
        "colab_type": "text"
      },
      "source": [
        "# To Do\n",
        "\n",
        "- Query P(A|B=0)\n",
        "- Add BC Plate\n",
        "- Check if training on only A improves performance\n",
        "- Formalize in Overleaf\n",
        "- Answer general research questions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ_f2Kmg7H9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}