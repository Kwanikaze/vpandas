{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRF_VAE",
      "provenance": [],
      "collapsed_sections": [
        "6iNkadXIh0gD"
      ],
      "authorship_tag": "ABX9TyMM46S3D83MpzJxiuxkx/PX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kwanikaze/vpandas/blob/master/MRF_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaO7CHX93gN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iNkadXIh0gD",
        "colab_type": "text"
      },
      "source": [
        "# Load Data and Create Sample Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9UE259FbtK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create two datasets from global df that are one-hot encoded\n",
        "def OHE_sample(sample_df, features_to_OHE: list):\n",
        "  for feature in features_to_OHE:\n",
        "    feature_OHE = pd.get_dummies(prefix = feature,data= sample_df[feature])\n",
        "    sample_df = pd.concat([sample_df,feature_OHE],axis=1)\n",
        "  sample_df.drop(features_to_OHE,axis=1,inplace=True)\n",
        "  print(sample_df)\n",
        "  return sample_df"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RykDGUc_-Q2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "0e2e6883-b37e-469c-df7a-1826fdd1dc4e"
      },
      "source": [
        "# Load global relation\n",
        "df = pd.read_csv(\"data_8.csv\")\n",
        "print(df.shape)\n",
        "\n",
        "#Create two datasets containing AB and BC\n",
        "num_samples = 1000\n",
        "sample1_df = df[['A','B']].sample(n=num_samples, random_state=2)\n",
        "print(sample1_df.head())\n",
        "sample2_df = df[['B','C']].sample(n=num_samples, random_state=3)\n",
        "print(sample2_df.head())\n",
        "\n",
        "# Make A,B,C inputs all 8 bits\n",
        "#Does data need to respect Gaussian distribution?\n",
        "sample1_OHE = OHE_sample(sample1_df,['A','B'])\n",
        "sample2_OHE = OHE_sample(sample2_df,['B','C'])\n",
        "\n",
        "# Could onvert pandas dataframes to list of lists of lists\n",
        "# [ [[OHE A1],[OHE B1]], [[OHE A2],[OHE B2]], ...  ]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5056, 3)\n",
            "      A  B\n",
            "4333  7  6\n",
            "2638  6  4\n",
            "2254  4  4\n",
            "3116  5  5\n",
            "3998  6  6\n",
            "      B  C\n",
            "4616  7  6\n",
            "2276  4  6\n",
            "3448  5  4\n",
            "4064  6  5\n",
            "1204  2  3\n",
            "      A_0  A_1  A_2  A_3  A_4  A_5  A_6  ...  B_1  B_2  B_3  B_4  B_5  B_6  B_7\n",
            "4333    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2638    0    0    0    0    0    0    1  ...    0    0    0    1    0    0    0\n",
            "2254    0    0    0    0    1    0    0  ...    0    0    0    1    0    0    0\n",
            "3116    0    0    0    0    0    1    0  ...    0    0    0    0    1    0    0\n",
            "3998    0    0    0    0    0    0    1  ...    0    0    0    0    0    1    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "1857    0    1    0    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "3813    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "604     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "621     1    0    0    0    0    0    0  ...    1    0    0    0    0    0    0\n",
            "1322    0    1    0    0    0    0    0  ...    0    1    0    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n",
            "      B_0  B_1  B_2  B_3  B_4  B_5  B_6  ...  C_1  C_2  C_3  C_4  C_5  C_6  C_7\n",
            "4616    0    0    0    0    0    0    0  ...    0    0    0    0    0    1    0\n",
            "2276    0    0    0    0    1    0    0  ...    0    0    0    0    0    1    0\n",
            "3448    0    0    0    0    0    1    0  ...    0    0    0    1    0    0    0\n",
            "4064    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "1204    0    0    1    0    0    0    0  ...    0    0    1    0    0    0    0\n",
            "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "3358    0    0    0    0    0    1    0  ...    0    0    0    0    0    1    0\n",
            "1496    0    0    1    0    0    0    0  ...    0    0    0    0    0    0    0\n",
            "4025    0    0    0    0    0    0    1  ...    0    0    0    0    1    0    0\n",
            "4689    0    0    0    0    0    0    0  ...    0    0    0    0    0    0    1\n",
            "2155    0    0    0    1    0    0    0  ...    0    0    1    0    0    0    0\n",
            "\n",
            "[1000 rows x 16 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvSWt2iUw9xE",
        "colab_type": "text"
      },
      "source": [
        "# Global Relation Bayesian Network Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubgZqS2rxNrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "outputId": "6ce14e17-4c66-4af0-d3f5-161abfc4f111"
      },
      "source": [
        "!pip install pgmpy==0.1.9\n",
        "import pgmpy\n",
        "import networkx as nx\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.inference import VariableElimination\n",
        "\n",
        "def groundTruth(df,evidence):\n",
        "    \"\"\"\n",
        "    Extracts ground truth from global relation\n",
        "    \"\"\"\n",
        "    model = BayesianModel([('B', 'A'), ('B', 'C')])\n",
        "    model.fit(df)\n",
        "    nx.draw(model, with_labels=True)\n",
        "    plt.show()\n",
        "    print('\\n Global Relation Ground Truth')\n",
        "    #for var in model.nodes():\n",
        "    #    print(model.get_cpds(var))\n",
        "    inference = VariableElimination(model)\n",
        "    q = inference.query(variables=['A','B','C'])\n",
        "    joint_prob = q.values.flatten()\n",
        "    #print(joint_prob)\n",
        "    #print('\\n P(A,B,C) \\n Ground Truth')\n",
        "    #print(q)\n",
        "    q = inference.query(variables=['C'], evidence=evidence)\n",
        "    print('\\n P(C|A=0) \\n Ground Truth')\n",
        "    print(q)\n",
        "\n",
        "groundTruth(df,{'A':0})"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pgmpy==0.1.9 in /usr/local/lib/python3.6/dist-packages (0.1.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Finding Elimination Order: : : 0it [00:00, ?it/s]\n",
            "0it [00:00, ?it/s]\n",
            "Finding Elimination Order: : 100%|██████████| 1/1 [00:00<00:00, 590.17it/s]\n",
            "Eliminating: B: 100%|██████████| 1/1 [00:00<00:00, 339.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Global Relation Ground Truth\n",
            "\n",
            " P(C|A=0) \n",
            " Ground Truth\n",
            "+------+----------+\n",
            "| C    |   phi(C) |\n",
            "+======+==========+\n",
            "| C(0) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(1) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(2) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(3) |   0.2500 |\n",
            "+------+----------+\n",
            "| C(4) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(5) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(6) |   0.0000 |\n",
            "+------+----------+\n",
            "| C(7) |   0.0000 |\n",
            "+------+----------+\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA3YIf_-iAm8",
        "colab_type": "text"
      },
      "source": [
        "# Create VAE-MRF Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45UMLBM0iE4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VAE Parameters\n",
        "latent_dims = 3\n",
        "num_epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate = 1e-3\n",
        "use_gpu = True\n",
        "variational_beta = 0.00001 #tuned"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0FiF8-RkNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VariationalAutoencoder(nn.Module):\n",
        "    def __init__(self, latent_dims):\n",
        "        super().__init__()\n",
        "        self.latent_dims = latent_dims\n",
        "        self.fc1 = nn.Linear(num, latent_dims) # why have this additional fc layer?\n",
        "        self.fc_mu = nn.Linear(latent_dims, latent_dims)\n",
        "        self.fc_logvar = nn.Linear(latent_dims, latent_dims)\n",
        "        #self.fc_mu = nn.Linear(num, latent_dims)\n",
        "        #self.fc_logvar = nn.Linear(num, latent_dims)\n",
        "        self.fc_out = nn.Linear(latent_dims,num)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = torch.sigmoid(self.fc1(x))\n",
        "        return self.fc_mu(h1), self.fc_logvar(h1)\n",
        "        #return torch.sigmoid(self.fc_mu(x)),torch.sigmoid(self.fc_logvar(x))\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        if z.size()[0] == self.latent_dims: #resize from [3] to [1,3]\n",
        "          z = z.view(1, self.latent_dims)\n",
        "        softmax = nn.Softmax(dim=1)\n",
        "        recon = softmax(self.fc_out(z))\n",
        "        return recon\n",
        "\n",
        "    def forward(self, x, latent_dims):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def latent(self,x,latent_dims):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z\n",
        "\n",
        "    def sample(self, num_samples):\n",
        "      # ignore latent_mu, latent_logvar, instead generate z values from standard normal\n",
        "      z = torch.randn(num_samples, self.latent_dims)\n",
        "      z = z.to(device)\n",
        "      samples = self.decode(z)\n",
        "      return samples\n",
        "\n",
        "def vae_loss(batch_recon, x_batch_targets, mu, logvar):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  CE = criterion(batch_recon, x_batch_targets)\n",
        "  #print(CE)\n",
        "  KLd = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # https://stats.stackexchange.com/questions/318748/deriving-the-kl-divergence-loss-for-vaes\n",
        "  #print(KLd)\n",
        "  return CE,variational_beta*KLd, CE + variational_beta*KLd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulCII451nHRR",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "Requires alternating between AB and BC samples. Have a separate plate for each.\n",
        "Need to learn Factors phi(A,B) and phi(B,C)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjRUnGgjnIvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}